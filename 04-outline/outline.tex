\documentclass[noindex,noinsetproof,12pt]{lmaths}
\addbibresource{../ors.bib}
\ExecuteBibliographyOptions{url=false}

\usepackage{tikz}
\usetikzlibrary{arrows}
\usetikzlibrary{cd}
\tikzcdset{arrow style=math font}

\setlist{leftmargin=3em}

\let\oldbeginabstract\abstract
\renewcommand{\abstract}{\oldbeginabstract\noindent}

\newcommand{\draftnote}[1]{\textcolor{red}{#1}}
\newcommand{\nearrowstar}{\mathclap{\nearrow}_{*}}
\newcommand{\searrowstar}{\mathclap{\searrow}^{*}}

\newtheorem{algorithm}[defn]{Algorithm}

\DeclareMathOperator{\WP}{WP}
\DeclareMathOperator{\FG}{FG}

\title{The Word Problem for One-Relation Semigroups}
\author{Lucas Jones}

\begin{document}

\maketitle
\bigskip
\tableofcontents

\section{Introduction} \label{sec:intro}

The aim of this project is to investigate the decidability of the word problem for so-called special one-relation monoids, via Zhang's application of string rewriting systems. In \cref{sec:intro}, we will recall some elementary definitions which will be useful throughout the project, before giving a brief history of the word problem for semigroups and, in particular, an overview of work which has been done for the special case of one-relator semigroups. In \cref{sec:rewriting-systems}, we provide an elementary introduction to string rewriting systems and their properties, which is crucial to \cref{sec:special-monoids}, an exposition of Zhang's proof in \cite{Zhang1992a} that the word problem for one-relation special monoids is decidable.

It is expected that the reader has a basic familiarity with the theory of semigroups, equivalent to the St Andrews module \emph{MT5826 Semigroups}, and an elementary acquaintance with groups.

\subsection{Free semigroups, monoids and groups}

An \dn{alphabet} is any finite set. The \dn{free semigroup} over this alphabet, denoted $A^{+}$, is the set of all nonempty finite strings made up of letters from $A$, equipped with the operation of concatenation.

The \dn{free monoid} $A^*$ over $A$ is the set $A^+ \cup \{\epsilon\}$ under concatenation, where $\epsilon$ is the empty string. A \dn{language} (over $A$) is any subset of $A^*$.

The construction of a free group is more involved, since the existence of inverses forces there to be some relations between letters. Again, let $A$ be an alphabet and fix an arbitrary set $A^{-1}$ which is disjoint but in bijection with $A$. We will write $a^{-1}$ for the image of $a \in A$ under this bijection. For any letter $a \in A$, the strings $aa^{-1}$ and $a^{-1}a$ are known as \dn{trivial relators}. We say a word is \dn{freely reduced} if it contains no trivial relators.

We say that two words $u$ and $v$ in $(A \cup A^{-1})^*$ are related by an elementary move if one can transform $u$ into $v$ by adding or removing a trivial relator at some point in $u$. We extend this to an equivalence relation $\sim$ by saying that $u \sim v$ if $u$ is related to $v$ by a finite sequence of elementary moves.  Furthermore, we claim that this relation $\sim$ is a congruence, and that the resultant quotient monoid $(A \cup A^{-1})^*/{\sim}$ is a group, called the \dn{free group} on $A$ and denoted $\FG(A)$.

\subsection{Presentations}

Presentations are a concise way of defining a semigroup, monoid or group in terms of a set of generators and a set of relations between these generating elements.

\begin{defn}
	A \dn{presentation} is an alphabet $A$ together with a set of `relations' $R \subseteq A^+ \times A^+$. Normally this is written $\langle A \mid R\rangle$, or $\langle A \mid a_1 = b_1, a_2 = b_2, \cdots \rangle$, if $R = \{(a_1, b_1), (a_2, b_2), \ldots\}$.
\end{defn}

The idea is that the letters in $A$ generate a semigroup (or monoid, or group) and we want the relations in $R$ and their consequences to be the only equations which are true in the semigroup. In a sense, the semigroup (or monoid, or group) presented by a presentation is the `largest' semigroup in which these equations are true.

\begin{defn}
	If $\langle A \mid R \rangle$ is a presentation, the \dn{semigroup presented by} $\langle A \mid R\rangle$ is quotient semigroup $A^+/\rho$, where $\rho$ is the smallest congruence on $A^+$ containing $R$. This is also denoted $\langle A \mid R \rangle$.
\end{defn}

For example, the free semigroup on two letters $F_2$ is presented by $\langle a, b \mid \rangle$. As another example, the presentation $\langle a \mid a^7 = a \rangle$ defines the cyclic group of order 6.

This definition extends very naturally to monoids.

\begin{defn}
	The \dn{monoid presented by a presentation} $\langle A \mid R\rangle$ is the quotient monoid $\Mon \langle A \mid R\rangle = A^*/\rho$, where $\rho$ is the smallest congruence on $A^*$ containing $R$. This is also denoted $\langle A \mid R \rangle$.
\end{defn}

The bicyclic monoid, for example, can be written as $\Mon \langle b, c \mid bc = \epsilon \rangle$. This is equivalent to the semigroup presentation $\langle b, c, \epsilon \mid bc = \epsilon, b\epsilon = \epsilon b = b, a\epsilon = \epsilon a = a, \epsilon^2 = \epsilon \rangle$.

A group presentation is defined in a similar way to the above, except that we need to include the trivial relations $aa^{-1} = a^{-1}a = \epsilon$ implied by the group axioms.

\begin{defn}
	The \dn{group presented by a presentation} $\langle A \mid R\rangle$, is the quotient monoid $\Gp \langle A \mid R\rangle = A^*/\rho$, where $\rho$ is the smallest congruence on $A^*$ containing $R$ and the trivial relations, namely $aa^{-1} = e$ and $a^{-1}a = \epsilon$ for each $a \in A$.
\end{defn}

To give a final example, the dihedral group of order 6 is given by the presentation $\Gp \langle \rho, \sigma \mid \rho^3 = \epsilon, \sigma^2 = \epsilon, \sigma\rho = \rho\sigma^{-1} \rangle$.

In this project, we will be interested mostly in \dn{finitely presented} semigroups, monoids and groups; that is, those structures which admit a presentation $\langle A \mid R\rangle$ where both $A$ and $R$ are finite. Not every semigroup is finitely presented, however. In particular, $\langle a, b \mid ab^ia = aba \quad\forall i \in \mathbb{N} \rangle$ defines a semigroup which is not finitely presented.

\subsection{Decidable and undecidable problems}

%In the 1930s, the discovery that several natural models of computation (such as Turing machines and Church's $\lambda$-calculus among others) were equally powerful provided strong motivation for most mathematicians to accept that for a procedure to be able to be solved by an algorithm meant that it could be solved by, for example, a Turing machine. With a concrete definition of computability came problems which were proven not to be computable. Turing described his machines for the first time in the 1936 paper \emph{On computable numbers with an application to the \emph{Entscheidungsproblem}}, which he used to prove the existence of these undecidable problems. He showed that the so-called halting problem was undecidable.

Fix an alphabet $A$ and let $L$ be a language over $A$. Then the \dn{decision problem} for $L$ takes as input a word $w$ in $A^*$ and outputs `true' if $w$ belongs in $L$ and `false' if it does not. A decision problem is said to be \dn{decidable} if there is an algorithm which always answers true or false in a finite number of steps, no matter what word $w$ is given as input, or \dn{undecidable} if no such algorithm exists.

One famous decision problem, which motivated much study in the early 20th century, is the \emph{Entscheidungsproblem} posed by Hilbert in the 1920s. Roughly speaking, the language $L$ in this case is the set of logical statements, described in terms of an appropriate alphabet, which are true assuming some set of axioms. Hilbert's challenge was to find an algorithm to solve this decision problem.

Church and Turing proved (independently) in the 1930s that it is not. However, to do so, they had to formalise the notion of `algorithm'. The intuitive concept of an algorithm has, of course, existed for thousands of years --- however, in order to prove that none exists for a particular problem, a mathematically rigorous definition is required. Until this was available, questions such as Hilbert's, as well as some about groups and semigroups which we will discuss in \hyperref[sec:word-problem]{the next section}, could not be answered negatively. The word problem for a group was defined some time before this, but the only results concerning it were algorithms to solve it for particular classes of groups. It was only afterwards that it could be proven that the word problem is undecidable in general, for example. 

A more elementary example of an undecidable problem is the \dn{halting problem}. As input, it takes a description of an algorithm and an input word $w$. In return, it outputs `true' if the algorithm completes in a finite number of steps --- or \dn{halts} --- given the input $w$, and `false' if it runs indefinitely.

\begin{theorem}
	The halting problem is undecidable.
\end{theorem}
\begin{proof}
	Suppose the halting problem were decidable, so that there exists an algorithm $H(A, X)$ which returns in finite time whether or not the algorithm $A$ halts given input $X$. Define a new algorithm $S(A)$, as follows: 
	\begin{enumerate}	
		\item Compute $H(A, A)$, i.e. whether the algorithm $A$ halts given a description of $A$ as input.
		\item If $A$ does halt on input $A$, loop forever.
		\item Otherwise, output `true' and halt.
	\end{enumerate}

	Now consider the result of applying $S$ to a description of itself. If $S$ halts on $S$, then by definition $H(S, S)$ must have been false. But this means that $S$ does not halt on input $S$, which is a contradiction. On the other hand, by assumption, our algorithm $H$ never halts. So if $S$ does not halt on $S$, $H(S, S)$ must be false --- but this is also a contradiction! So such an algorithm $H$ can not exist.
\end{proof}


\subsection{The word problem for groups} \label{sec:word-problem}

The word problem is one of three fundamental decision problems associated with a group introduced by Dehn in 1911, the others being the conjugacy problem and the isomorphism problem.

\begin{defn}
	Let $G = \Gp \langle A \mid R \rangle$ be a group. Then the \dn{word problem} for $G$, denoted $\WP(G)$, is the set
	\[ \WP(G) = \{ (u, v) \mid u, v \in A^*, u =_G v \} \]
	of pairs of words in the generators $A$ which are equal in $G$. The \dn{conjugacy problem} for $G$ is the set
	\[ \{ (u, v) \mid u, v \in A^*, \exists\ w \in G \colon u = w^{-1}vw \} \]
	of pairs of words which represent conjugate elements.
\end{defn}

The isomorphism problem is slightly different: it asks, given two presentations $\langle A \mid R \rangle$ and $\langle B \mid S \rangle$, whether the groups they present are isomorphic.

Each of these problems is readily generalisable to finitely presented semigroups. Axel Thue discussed the word problem for semigroups as early as 1914; interestingly, by considering what we would now call rewriting systems (as we will in \cref{sec:rewriting-systems}) rather than semigroups as algebraic structures\footnote{In \cite{Thue1914}; see the translation and commentary in \cite{Power2013}.}.

The word problem is readily solvable for certain classes of groups. For example, if $G$ is a free group, the algorithm is as follows: suppose $G$ is freely generated by a set $A$, and suppose that we have two elements $u$ and $v$ of $G$, written as words in $A$ and the corresponding inverse letters. Then since there are no relations in the group except those that follow from the group axioms, namely $aa^{-1} = a^{-1}a = \epsilon$ for each $a \in A$, we can iterate through the string, removing all of these pairs. Then $u =_G v$ if and only if these `reduced' words are equal, letter for letter.

In 1947, however, Emil Post proved that the general word problem for finitely-presented semigroups is undecidable; and shortly afterwards, in 1950, Turing himself showed that the word problem for cancellative finitely-presented semigroups is undecidable. The 1950s saw Novikov and Boone independently prove that the word problem for a general finitely-generated group is undeciadble.

Some important classes of groups and semigroups do, however, have decidable word problems. All finite groups and semigroups have decidable word problem. The special case which we shall be most concerned with in this project is that of the word problem of one-relation groups and semigroups.

\subsection{One-relation groups and semigroups}

A one-relation group or semigroup is a finitely presented group or semigroup which admits a presentation of the form $\langle A \mid u = v\rangle$, where $u$ and $v$ are words in $A^*$. The word problem for one-relator groups was in fact solved by Magnus in the early 1930s.

\begin{theorem}[Magnus, 1932] \label{thm:orgp-decidablewp}
	Let $G$ be a group admitting a presentation of the form $\langle A \mid u = v\rangle$, where $u$ and $v$ are words over the generating set $A$. Then the word problem for $G$ is decidable.
\end{theorem}

In his proof, Magnus relies heavily on the following result on the structure of one-relator groups, known as the \emph{Freiheitssatz}:

\begin{theorem}[Freiheitssatz] \label{thm:freiheitssatz}
	Let $G = \Gp \langle A \mid w = \epsilon \rangle$ be a one-relator group, with $w$ cyclically reduced, and let $a \in A$ be a letter contained in $w$. Then the subgroup $\langle A \setminus \{a\} \rangle$ is a free group.
\end{theorem}

Here, a word is said to be \dn{cyclically reduced} if all cyclic permutations of it are freely reduced --- e.g. $aba^{-1}$ is freely reduced but not cyclically reduced, since $a^{-1}ab$ is a cyclic permutation containing the trivial relator $a^{-1}a$. Modern proofs of the above theorems can be found in \cite{Lyndon2001}.

While the word problem for one-relator groups is in a sense completely solved, it is currently an open problem as to whether the word problem for one-relator semigroups is decidable. In this project, we consider a significant special case first proved by Adjan in the 1960s \cite{Adian1966}:

\begin{defn}
We say a one-relator monoid is \dn{special} if it admits a finite presentation of the form $\langle A \mid r = \epsilon \rangle$.
\end{defn}

\begin{theorem}[Adjan]
	Let $M$ be a one-relator special monoid. Then $M$ has decidable word problem.
\end{theorem}

There is a monoid analogue to the Freiheitssatz, due to Squier and Wrathall (\cite{Squier1983}):
% XXX check this XXX
\begin{theorem}[Freiheitssatz for one-relator monoids]
	Let $S = \langle A \mid u = v \rangle$ be a one-relator group, with $w$ cylically reduced, and let $a \in A$ be a letter contained in $uv$. Then the submonoid $\langle A \setminus \{a\} \rangle$ is free.
\end{theorem}
However, perhaps surprisingly, while both Zhang's proof and Adjan's original proof of the result for one-relator special monoids rely crucially upon the Freiheitssatz for groups, it does not use the monoid result at all.


\section{Rewriting systems} \label{sec:rewriting-systems}

\subsection{Introduction}

A \dn{string rewriting system} over an alphabet $A$ is a set $R \subseteq A^* \times A^*$ of rules, normally written $\{u_1 \to v_1, u_2 \to v_2, \ldots\}$. The rules specify the action of the rewriting system on a string: each rule $u \to v$ specifies that whenever $u$ appears as a substring, it should be replaced by the string $v$. Formally:

\begin{defn}
	Let $R$ be a string rewriting system over an alphabet $A$. Then the \dn{rewriting relation} $\to_R$ (or often just $\to$) is defined as follows: if $u, v \in A^*$, then $u \to_R v$ if and only if there exist strings $A, B \in A^*$ and a rule $(w, z) \in R$ such that $u = AwB$ and $v = AzB$.
\end{defn}

\begin{example} \label{ex:rws1}
	Let $R$ be the rewriting system $\{ bb \to a, aa \to b \}$. Then $abba \to aaa$, $aaa \to ba$ and $aaa \to ab$. On the other hand, $a \nrightarrow bb$, $bba \nrightarrow ba$ and $abba \nrightarrow ab$.
\end{example}

Two strings are related under this relation if the right hand side is the result of making exactly one replacement according to a single rule in the corresponding rewriting system. Often it is useful to consider strings arising after an arbitrary number of replacements:

\begin{defn}
	The \dn{transitive closure} of the rewriting relation $\to_R$, denoted $\to_R^*$, is the smallest transitive relation on $A^*$ containing $\to_R$. Equivalently, two strings $u, v \in A^*$ are related under $\to_R^*$ if there exist strings $u_1, u_2, \ldots, u_n \in A^*$ (for some $n \ge 0$) such that $u \to_R u_1 \to_R u_2 \to_R \cdots \to_R u_n \to_R v$.
\end{defn}

Continuing \cref{ex:rws1}, while $abba \nrightarrow ab$, it is true that $abba \to^* ab$.

Let $u, v, w \in A^*$ be strings. If $u \to^* w$, then we say that $v$ is a \dn{descendant} of $u$. Furthermore, if it is also true that $v \to^* w$, then we say that $w$ is a \dn{common descendant} of $u$ and $v$. Whether or not a given string has a descendant is an important question when we are considering the termination properties of a string rewriting system. In particular, the `irreducible' strings are crucial:

\begin{defn}
	A word $u$ is \dn{irreducible} if it has no descendants; i.e. if there is no word $v$ such that $u \to v$.
\end{defn}

\subsection{Equivalences and presentations}

We can further extend the rewriting relation to an equivalence relation.

\begin{defn}
	The \dn{symmetric closure} of the rewriting relation $\to_R$, denoted $\leftrightarrow_R$, is defined such that for two words $u, v \in A^*$, $u \leftrightarrow_R v$ if and only if $u \to_R v$ or $v \to_R u$.
\end{defn}

\begin{defn}
	Given a string rewriting system $R$, the relation \dn{equivalence modulo $R$}, denoted $=_R$, is the smallest equivalence relation containing $R^*$. Equivalently, if $u, v \in A^*$ are two words, then $u =_R v$ if there exist strings $u_1, u_2, \ldots, u_n \in A^*$, for some $n \ge 1$, such that $u = u \leftrightarrow u_1 \leftrightarrow u_2 \leftrightarrow \cdots \leftrightarrow u_n = v$.
\end{defn}

In the above definition, taking $n = 1$ leaves no conditions to check, so $u =_R u$ for all strings $u \in A^*$.

\label{sec:rws-presentations} The usefulness of this equivalence relation for our purposes becomes apparent when we identify rewriting systems with monoid presentations. Suppose we have a presentation $\Mon \langle A \mid R\rangle$. Then picking a `direction' for each equation in $R$, we can write $R = \{ (r_1, s_1), (r_2, s_2), \ldots \}$. This set $R$ also forms a string rewriting system over $A^*$, and the equivalence $=_R$ is exactly the word problem for the monoid $M = \Mon \langle A \mid R\rangle$. Furthermore, $=_R$ is also a congruence on $A^*$, and the quotient $A^*/{=_R}$ is isomorphic to $M$.

\subsection{Noetherian rewriting systems}

Noetherianness is one property we put on a rewriting system to ensure its rewriting algorithm (see \ref{sec:normal-forms}) always terminates, no matter which string it is applied to. It is very useful to know that a rewriting system is noetherian if one wants to prove, as we will later, that an algorithm which uses it also always terminates. Before discussing noetherianness, we need to make some definitions relating to partial orders.

\begin{defn}
	A linear order on a set $X$ is a relation $<$ on $X$ which has the following properties for all $a, b, c \in X$:
	\begin{itemize}
		\item \emph{Trichotomy:} exactly one of $a < b$, $b < a$ or $a = b$ holds.
		\item \emph{Transitivity:} if $a < b$ and $b < c$, then $a < c$.
	\end{itemize}
\end{defn}

\begin{defn}
	An order $<$ on a set $X$ is \dn{well-founded} if there is no sequence $x_1, x_2, \ldots \in X$ such that
	\[ x_1 < x_2 < x_3 < \cdots. \]
\end{defn}

An interesting application of well-foundedness is the concept of noetherian induction, which generalises regular mathematical induction to any set equipped with a well-founded order.

\begin{prop}[Noetherian induction] \label{prop:noetherian-induction}
	Let $P(x)$ be a property of elements of a set $X$, and suppose that $\rightarrow$ is a well-founded order on $X$. Then $P(x)$ is true for all $x \in X$ if for any $y \in X$, $P(y)$ is true if $P(z)$ is true for all $z \ne y$ such that $y \rightarrow^* z$. That is, if $P(y)$ is true whenever $P$ is true for every descendant of $y$.
\end{prop}
\begin{proof}
	Suppose that for each $y \in X$, $P(y)$ is true if $P(z)$ is true for all descendants $z$ of $y$, and suppose there is some $x \in X$ such that $P(x)$ is false. If $x$ has no descendants, then $P(x)$ is vacuously true. So $x$ must have a descendant $x_2$ such that $P(x_2)$ is false. By the same reasoning $x_2$ must have a descendant $x_3$ such that $P(x_3)$ is false. Continuing in this fashion, we have an infinite chain of descendants
		\[ \cdots \to x_3 \to x_2 \to x, \]
	for each of which $P$ is false. But this contradicts $\to$ being well-founded, since by definition a well-founded relation has no infinite chains.
\end{proof}

The usual notion of induction on the natural numbers is the same as the above if $\mathbb{N}$ is equipped with its natural order, which is clearly well-founded.

We can now define the notion of a noetherian rewriting system in terms of its reduction relation.

\begin{defn}
	A noetherian rewriting system is a rewriting system whose reduction relation $\rightarrow$ is well-founded.
\end{defn}

The crucial consequence of this is the following:

\begin{prop}
	In a noetherian rewriting system, every string has an irreducible descendant. \label{prop:noetherian-every-irred}
\end{prop}
\begin{proof}
	Suppose $R$ is a noetherian rewriting system, and that $u \in A^*$ does not have an irreducible descendant. Then it must have some descendant $u_1 \in A^*$ such that $u \to u_1$, or $u$ itself would be irreducible. But $u_1$ must also have no irreducible descendants, since any of its irreducible descendants would also be irreducible descendants of $u$. Applying this reasoning to $u_1$, there must be a word $u_2 \in A^*$ such that $u_1 \to u_2$ and $u_2$ has no irreducible descendants. Continuing in this manner, we have a sequence of strings
		\[ u_1 \to u_2 \to u_3 \to \cdots; \]
	but since $R$ is noetherian, $\to$ is well-founded and so this is a contradiction.
\end{proof}

One way of showing a rewriting system is noetherian is to define a well-founded linear order $>$ on the set of strings $A^*$, and show that whenever $(u, v)$ is a rule in $R$, $u > v$. One common order which can be applied to many practical rewriting systems is the short-lexicographic order, which takes an order $\succ$ on the alphabet $A$ and extends it to a useful order on the whole set of strings $A^*$. Our examples thus far have mostly used the alphabet $\{a, b, c\}$, on which there is an `obvious' order to extend, $c \succ b \succ a$.

\begin{defn}
	Let $A$ be an alphabet, and let $\succ$ be a linear order on $A$. Then the \dn{short-lexicographic}, or \dn{short-lex order} $>$ on $A^*$ extending $\succ$ is defined as follows: suppose $u = u_1\cdots u_m, v = v_1\cdots v_n \in A^*$ are words. Then $u > v$ if and only if
	\begin{enumerate}[(i)]
		\item $m > n$; or
		\item $m = n$ and there exists an index $1 \le i \le n$ such that $u_j = v_j$ for all $1 \le j > i$ and $u_i \succ v_i$.
	\end{enumerate}
\end{defn}

It remains to show that the order as defined is suitable for the purposes we described above:
\begin{lemma}
	The short-lexicographic order is, in fact, a linear order.
\end{lemma}
\begin{proof}
	Let $A$ be an alphabet equipped with a linear order $\succ$ and let $>$ be the short-lex order extending $\succ$. Suppose $a, b, c \in A^*$, and assume that $|a| \ge |b| \ge |c|$. To show $>$ satisfies the trichotomy condition, we show that if $a \ne b$, one of $a > b$ or $b > a$ holds. If $a \ne b$, then either $a$ and $b$ have different lengths --- in which case $a > b$ --- or $|a| = |b|$ but they differ in at least one symbol. Let $i$ be the lowest $i \in \mathbb{N}$ such that $a_i \ne b_i$. Then since $\succ$ is a linear order, either $a_i \succ b_i$, in which case $a > b$; or $b_i \succ a_i$, in which case $b > a$. So the condition is satisfied.

	Finally, we show that $>$ is transitive. Suppose $a > b$ and $b > c$. If either $|a| > |b|$ or $|a| > |c|$, then $a > c$ follows immediately. So suppose $|a| = |b| = |c|$. Then since $a > b$, there is a lowest index $i \in \mathbb{N}$ such that $a_i \succ b_i$. Furthermore, since $b > c$, we must have $b_i = c_i$ or $b_i \succ c_i$. In either situation, $a_i \succ c_i$; and $a_1\cdots a_{i-1} = b_1\cdots b_{i-1} = c_1\cdots c_{i-1}$, so $a > c$ as required.

	Hence $>$ is indeed a linear order on $A^*$.
\end{proof}

\begin{prop}
	The short-lexicographic order is well-founded.
\end{prop}
\begin{proof}
	Let $A$ be an alphabet with a linear order $\succ$ extended to a short-lex order $>$ on $A^*$. Suppose we have an an infinite chain of words $u_1, u_2, \ldots \in A^*$ such that $u_1 > u_2 > \cdots$. Since the order $>$ on $\mathbb{N}$ is well-founded, the sequence $|u_1|, |u_2|, \ldots$ must eventually become constant, say at $|u_k|$. Then $|u_k| = |u_{k+1}| = |u_{k+2}| = \cdots$, so for $u_k > u_{k+1}$ to be true, the strings must differ at some index $i_1$. Then for $u_k > u_{k+1} > u_{k+2}$ to be true, $u_{k+1}$ and $u_{k+2}$ must differ at some index $i_2 \ge i_1$.
	
	Continuing for $u_{k+3}$ and so on, we obtain a nondecreasing sequence $i_1, i_2, \ldots$ of these indices. A particular index can only be repeated at most $|A|$ times, or we run out of letters in the alphabet which can be greater than the one in the corresponding place in the previous string. But the indices are bounded by $|u_k|$, so such an (infinite) sequence can not exist, and so neither can the words $u_1 > u_2 > \cdots$.
\end{proof}

\subsection{Confluence}

While noetherianness is useful in showing the rewriting algorithm terminates, for the answer it produces to be useful as a normal form, we want the resulting irreducible descendant to be unique. Without imposing extra conditions, it is possible that one string could have multiple irreducible descendants depending on which rules were chosen at each stage.

\begin{example}
	A very simple example of a non-confluent rewriting system is
		\[ R = \{ ab \to a, ab \to b \}. \]
\end{example}

\begin{defn}
	A rewriting system $R$ over an alphabet $A$ is \dn{confluent} if for all strings $a, b, c \in A^*$, whenever $a \to_R^* b$ and $a \to_R^* c$, there exists a string $z \in A^*$ such that $b \to^*_R z$ and $c \to^*_R z$.
\end{defn}

\begin{defn}
	A rewriting system $R$ over an alphabet $A$ is \dn{locally confluent} if for all strings $a, b, c \in A^*$, whenever $a \to_R b$ and $a \to_R c$, there exists a string $z \in A^*$ such that $b \to^*_R z$ and $c \to^*_R z$.
\end{defn}

\begin{theorem}[Newman] \label{thm:newman}
	If $R$ is a noetherian rewriting system, then $R$ is confluent if and only if it is locally confluent.
\end{theorem}

This theorem is often known as Newman's lemma, having first been proven by Newman in \cite{Newman1942}. Here we follow a simpler proof due to Huet written using the modern language of rewriting systems, which appears in \cite{Huet1980}. The principal technique of this proof is the notion of Noetherian induction (\cref{prop:noetherian-induction}).

\begin{proof}[ \pCref{thm:newman}]
	It is clear that a confluent system is locally confluent, since if $x \to z$ then $x \to^* z$ for all $x, z \in A^*$.

	Conversely, suppose $R$ is a locally confluent rewriting system over an alphabet $A$. We shall prove the statement $P(x)$ over $A^*$ by noetherian induction, defining $P(x)$ to be true if and only if for all $X, X' \in A^*$ such that $x \to^* X$ and $x \to^* X'$, there exists $z \in A^*$ such that $X \to^* z$ and $X' \to^* z$. If $P(x)$ holds for all strings $x$, the system is confluent by definition. 

	Let $x \in A^*$ be such that $P(x)$ holds for all its descendants. Let $X, X' \in A^*$ be such that $x \to_R^* X$ and $x \to_R^* X'$. In particular, because $\to$ is noetherian, there exist finite derivations $x = x_1 \to_R x_2 \to_R \cdots \to_R x_m = X$ and $x = x_1' \to_R x_2' \to_R \cdots \to_R x_n' = X'$. Since $R$ is locally confluent, the fact that $x \to_R x_1$ and $x \to_R x_1'$ means there exists a string $u \in A^*$ such that $x_1 \to_R^* u$ and $x_1' \to_R^* u$:

	{\centering
	\begin{tikzcd}
		& \arrow[dl] x \arrow[dr] \\
		x_1 \arrow[dd, "*"'] \arrow[dr, "*"] & & x_1' \arrow[dd, "*"] \arrow[dl, "*"'] \\
		& u & \\
		X & & X'
	\end{tikzcd}
	\par}

	Since $x_1$ is a descendant of $x$, by the inductive hypothesis, there exists a $v \in A^*$ such that $u \to^* v$ and $X \to^* v$.

	{\centering
	\begin{tikzcd}
		& \arrow[dl] x \arrow[dr] \\
		x_1 \arrow[dd, "*"'] \arrow[dr, "*"] & & x_1' \arrow[dd, "*"] \arrow[dl, "*"'] \\
		& u \arrow[ddl, "*"] & \\
		X \arrow[d, "*"'] & & X' \\
		v
	\end{tikzcd}
	\par}

	Next, since $x_1'$ is a descendant of $x$, by the inductive hypothesis there is a string $w \in A^*$ such that $u \to^* w$ and $X' \to^* w$.

	{\centering
	\begin{tikzcd}
		& \arrow[dl] x \arrow[dr] \\
		x_1 \arrow[dd, "*"'] \arrow[dr, "*"] & & x_1' \arrow[dd, "*"] \arrow[dl, "*"'] \\
		& u \arrow[ddl, "*"] \arrow[ddr, "*"'] & \\
		X \arrow[d, "*"'] & & X' \arrow[d, "*"] \\
		v & & w
	\end{tikzcd}
	\par}

	To complete the proof, we observe that $u$ is a descendant of $x$, so there is a string $z \in A^*$ such that $v \to^* z$ and $w \to^* z$.

	{\centering
	\begin{tikzcd}
		& \arrow[dl] x \arrow[dr] \\
		x_1 \arrow[dd, "*"'] \arrow[dr, "*"] & & x_1' \arrow[dd, "*"] \arrow[dl, "*"'] \\
		& u \arrow[ddl, "*"] \arrow[ddr, "*"'] & \\
		X \arrow[d, "*"'] & & X' \arrow[d, "*"] \\
		v \arrow[dr, "*"] & & w \arrow[dl, "*"'] \\
		& z & 
	\end{tikzcd}
	\par}

	Thus we have found a $z$ such that $x_1 \to^* z$ and $x_1' \to^* z$ as required.
\end{proof}

In order to show that a rewriting system is confluent, we can use the following condition, a restatement of theorem 1 given without proof in \cite{McNaughton1987}:
\begin{theorem} \label{thm:confluent-cond}
	A rewriting system $R$ over an alphabet $A$ is locally confluent if and only if the following hold for all strings $u, v, w, x, y \in A^*$:
	\begin{enumerate}[(1)]
		\item \label{it:conf-overlap} If $uv \to x$ and $vw \to y$ are rules of $R$ then there is a $z \in A^*$ such that $xw \to^*_R z$ and $uy \to^*_R z$.
		\item \label{it:conf-middle} If $uvw \to x$ and $v \to y$ are rules of $R$ then there is a $z \in A^*$ such that $x \to^*_R z$ and $uyw \to^*_R z$.
	\end{enumerate}
\end{theorem}

In fact, a rewriting system is confluent, not just locally confluent, if it satisfies the above condition. However, local confluence is sufficient for our purposes because the rewriting system we will consider in \cref{sec:special-monoids} is noetherian so we can apply \cref{thm:newman}.

\begin{proof}[ \pCref{thm:confluent-cond}]
	The `only if' direction is straightforward. To show the `if' direction, suppose $a, x, y$ are strings such that $a \to_R x$ through a rule $u \to v$ and $a \to_R y$ through a rule $u' \to v'$. Then $a$ contains $u$ as a substring, i.e. $a = AuZ$ for some $A, Z \in A^*$. The string $u'$ must also occur somewhere in $a$. There are five possibilities for its location, and in each case we show that a common descendant $z \in A^*$ exists for $x$ and $y$ and hence that $R$ is locally confluent.

	\textbf{Case (i)}: $u'$ is entirely contained in $A$. Write $a = Bu'CuZ$, so that $A = Bu'C$. Then \[
		\begin{array}{lllll}
			& & Au'CvZ & & \\
			& \nearrow & & \searrow & \\
			a = Bu'CuZ & & & & Av'CvZ, \\
			& \searrow & & \nearrow & \\
			& & Av'CuZ & &
		\end{array}
	\]
	so $z = Av'CvZ$ works.

	\textbf{Case (ii)}: $u'$ is contained in $Au$ but not in $A$ or $u$. Factor $a = BCDEZ$ as follows, so that $u = DE$ and $u' = CD$:

	{\centering
	\begin{tikzpicture}
		\filldraw[fill=gray!20] (0,0) rectangle (2,0.5) node[midway] {$A$};
		\draw[<->] (0.05,0.6) -- (0.75,0.6) node[above,midway] {$B$};
		\draw[dashed] (0.8,0) -- (0.8,0.5);
		\draw[<->] (0.85,0.6) -- (1.95,0.6) node[above,midway] {$C$};
		\draw[solid] (2,0) -- (2,0.5);
		\filldraw[fill=gray!20] (2,0) rectangle (4,0.5) node[midway] {$u$};
		\draw[<->] (2.05,0.6) -- (2.75,0.6) node[above,midway] {$D$};
		\draw[<->] (0.85,-0.1) -- (2.75,-0.1) node [below,midway] {$u'$};
		\draw[dashed] (2.8,0) -- (2.8,0.5);
		\draw[<->] (2.85,0.6) -- (3.95,0.6) node[above,midway] {$E$};
		\filldraw[fill=gray!20] (4,0) rectangle (6,0.5) node[midway] {$Z$};
	\end{tikzpicture}\par}

	Then we have rules $CD \to v'$ and $DE \to v$ in $R$, so by hypothesis there is a $z \in A^*$ such that $v'E \to^*_R z$ and $Cv \to^*_R z$, and we have a common descendant like so: \[
		\begin{array}{lllll}
			& & Bv'EZ & & \\
			& \nearrow & & \searrowstar & \\
			a = BCDEZ & & & & BzZ. \\
			& \searrow & & \nearrowstar & \\
			& & BCvZ & &
		\end{array}
	\]

	\textbf{Case (iii)}: $u'$ is entirely contained in $u$. Factor $a = ABu'CZ$ so that $u = Bu'C$. Then by hypothesis there is a $z \in A^*$ such that $v \to^* z$ and $Bv'C \to^* z$. So we have the diagram: \[
		\begin{array}{lllll}
			& & ABv'CZ & & \\
			& \nearrow & & \searrowstar & \\
			a = ABu'CZ & & & & AzZ. \\
			& \searrow & & \nearrowstar & \\
			& & AvZ & &
		\end{array}
	\]

	\textbf{Case (iv)}: $u'$ is contained in $uZ$ but not in $u$ or $Z$. Factor $a = ABCDE$ as below, so that $u = BC$, $u' = CD$ and $Z = DE$:

	{\centering
	\begin{tikzpicture}
		\filldraw[fill=gray!20] (0,0) rectangle (2,0.5) node[midway] {$A$};
		\draw[<->] (2.05,0.6) -- (2.75,0.6) node[above,midway] {$B$};
		\draw[<->] (2.85,0.6) -- (3.95,0.6) node[above,midway] {$C$};
		\draw[solid] (2,0) -- (2,0.5);
		\filldraw[fill=gray!20] (2,0) rectangle (4,0.5) node[midway] {$u$};
		\draw[<->] (4.05,0.6) -- (4.75,0.6) node[above,midway] {$D$};
		\draw[dashed] (2.8,0) -- (2.8,0.5);
		\draw[<->] (4.85,0.6) -- (5.95,0.6) node[above,midway] {$E$};
		\filldraw[fill=gray!20] (4,0) rectangle (6,0.5) node[midway] {$Z$};
		\draw[dashed] (4.8,0) -- (4.8,0.5);
		\draw[<->] (2.85,-0.1) -- (4.75,-0.1) node [below,midway] {$u'$};
	\end{tikzpicture}\par}

	Since we have rules $BC \to v$, $CD \to v'$, by hypothesis there is a $z \in A^*$ such that $vD \to^* z$ and $Bv' \to z$, giving the diagram: \[
		\begin{array}{lllll}
			& & AvDE & & \\
			& \nearrow & & \searrowstar & \\
			a = ABCDE & & & & AzZ. \\
			& \searrow & & \nearrowstar & \\
			& & ABv'E & &
		\end{array}
	\]

	\textbf{Case (v)}: $u'$ is entirely contained in $Z$. This case is very similar to case (i) and is omitted.
\end{proof}

\begin{prop}
	In a confluent rewriting system a string has at most one irreducible descendant. \label{prop:confluent-at-most-one}
\end{prop}
\begin{proof}
	Let $R$ be a confluent rewriting system over an alphabet, and let $u \in A^*$. Suppose $u$ had two irreducible descendants $u'$ and $u''$ in $A^*$. Then since $R$ is confluent, there exists a string $v \in A^*$ such that $u' \to^* v$ and $u'' \to^* v$. But since both these strings are irreducible, the only way for $u' \to^* v$ to be true is if $u' = v$, and hence $u' = v = u''$. Therefore if $u$ has an irreducible descendant, it must be unique.
\end{proof}

\subsection{Normal forms} \label{sec:normal-forms}

The idea of a normal form comes from the following result:

\begin{prop}
	With respect to a confluent noetherian rewriting system, every string $u \in A^*$ has exactly one irreducible descendant.
\end{prop}
\begin{proof}
	Let $R$ be a confluent noetherian rewriting system over an alphabet $A$, and let $u \in A^*$. Then since $R$ is noetherian, by \cref{prop:noetherian-every-irred} the word $u$ has an irreducible descendant $u' \in A^*$. Finally, by \cref{prop:confluent-at-most-one}, this irreducible descendant $u'$ must be unique.
\end{proof}

We refer to this irreducible descendant $u'$ as the \dn{normal form} for $u$, which will for a general word $u$ be denoted $\bar u$. We can in fact say more than this:

\begin{theorem}
	Let $R$ be a confluent noetherian rewriting system and $u \in A^*$. Then if $u =_R v$, then $\bar u =_R \bar v$.
\end{theorem}
\begin{proof}
	Let $R$ be such a rewriting system, and let $u, v \in A^*$ such that $u =_R v$. Since $u \to_R^* \bar u$, $u =_R \bar u$; and since $v \to_R^* \bar v$, $v =_R \bar v$ and so by transitivity of $=_R$, $\bar u =_R \bar v$.
\end{proof}

Recall from \cref{sec:rws-presentations} that if we have a presentation $\Mon \langle A \mid R \rangle$, the monoid it presents is given by the quotient $A^*/{=_R}$. Thus the theorem above gives each equivalence class, i.e. every element in the monoid, a unique representative. If we had a way of computing this normal form for an element given by any word, we could compare two elements --- i.e. solve the word problem --- by computing their normal forms and comparing those letter by letter.

Since we are considering confluent noetherian rewriting systems, the following simple algorithm accomplishes this very task:

\begin{algorithm} The rewriting algorithm: \label{alg:rewrite}

\hspace{0.05\textwidth}
\parbox[t]{0.9\textwidth}{
	\textbf{Input:} a confluent noetherian rewriting system $R$ over an alphabet $A$; a word $w \in A^*$ \\
	\textbf{Output:} the normal form $\bar w$ of $w$
	\medskip

	\begin{enumerate}
		\item Let $w' \leftarrow w$.
		\item For every rule $u \to v$ in $R$:	\label{nfal-for-every-rule}
			\begin{enumerate}
				\item Scan the string $w'$ from left to right to try to find an occurence of $u$.
				\item If one is found, then we can write $w' = AuB$. Set $w' \leftarrow AvB$ and return to step \ref{nfal-for-every-rule}. It should be clear that $AuB =_R AvB$.
			\end{enumerate}
		\item If we reach this point, then $w'$ is irreducible and so we can set $\bar w \leftarrow w'$.
	\end{enumerate}
}
\end{algorithm}

The crucial question we ask about this algorithm is then: does it halt on any input? Since $R$ is assumed to be noetherian, the string can only be reduced finitely many times before we encounter an irreducible element. So the algorithm halts on any input as long as the number of rules in $R$ is finite (otherwise the loop in step \ref{nfal-for-every-rule} would never terminate). In fact, it is sufficient that there are only a finite number of rules which can apply to any particular $w'$, and that this set of rules can be enumerated in finite time. For example, if the set of rules was stored in order of the length of the left hand side, and there are only finitely many rules of any given length, then we can simply check all rules until the length of one exceeds the length of $w'$.

This is essentially the argument we will use in \cref{sec:special-monoids} to conclude that the word problem is decidable.

\section{The word problem for one-relation special monoids} \label{sec:special-monoids}

In this section, we discuss the word problem for a special class of one-relation semigroups, namely `special' one-relation monoids.

\begin{defn} \label{def:special}
	A monoid $M$ is \dn{special} if it has a presentation of the form $\langle A \mid w_1 = \epsilon, w_2 = \epsilon, \ldots, w_n = \epsilon \rangle$ for nonempty words $w_i \in A^*$.
\end{defn}

The main result is a theorem of Adjan, which states that the word problem is indeed decidable for one-relation special monoids:

\begin{theorem}[Adjan] \label{thm:ors-decidablewp}
	Let $M$ be a one-relation special monoid, i.e. a monoid admitting a presentation of the form $\langle A \mid w = \epsilon\rangle$, where $A$ is an alphabet, $w \in A^+$. Then $M$ has decidable word problem.
\end{theorem}

Here, we follow Zhang's proof from \cite{Zhang1992a}, which uses rewriting systems to obtain a dramatic simplification of Adian's first proof in \cite{Adian1966}. Zhang's overall approach is to construct a one-relation presentation for the group of units of the special monoid --- whose word problem is then decidable by Magnus' theorem --- and reduce the word problem of the whole monoid to that of the group of units using a confluent, noetherian rewriting system.

In another paper \cite{Zhang1992}, Zhang uses a similar method to generalise this statement by reducing the word problem of any special monoid to the word problem of its group of units, as well as obtaining similar results on the conjugacy and divisibility problems for these monoids.


\subsection{Constructing a generating set}

Suppose $M = \langle A \mid w = \epsilon\rangle$ is a finitely presented monoid.

Given a subset $X \subseteq A^*$ of words, define
	\begin{align*}
		L(X) &= \{ x \in A^+ \mid \exists\ w \in A^* \colon wx \in X \} \text{ and } \\
		R(X) &= \{ x \in A^+ \mid \exists\ w \in A^* \colon xw \in X \}
	\end{align*}
to be the set of left and right factors respectively of words in $X$, and let $W(X) = L(X) \cap R(X)$ be the set of words which are both left and right factors each of some word in $X$.

Taking $C_1 = \{w\}$, let
	\[ C_{i+1} = C_i \cup \{ xy \mid y \in W(C_i), yx \in C_i \} \cup \{ yz \mid y \in W(C_i), zy \in C_i \} \]
be those words obtained by moving right factors from $W(C_i)$ to the beginning of the words in $C_i$ in which they appear and left factors to the end of words.

To see why we do this, consider as an example the monoid $N = \langle a, b, c \mid bcab = \epsilon \rangle$. Clearly, the word $bcab$ is invertible in $N$, since it is the identity. Notice also that $L(\{bcab\}) \cap R(\{bcab\}) = \{b, bcab\}$. The letter $b$ appears at the start and end of the word: $bca \cdot b = \epsilon$ and $b \cdot cab = \epsilon$. That is, $bca$ is a left inverse for $b$ and $cab$ is a right inverse for $b$.

Since left and right inverses are the same, it must also follow that $b \cdot bca = \epsilon$ and $cab \cdot b = \epsilon$. These resulting words are also invertible in $N$, so we can repeat the process to gather together all the trivial words which arise in this way. We will discuss this more carefully in the proof of \cref{prop:M'-is-group}.


\begin{lemma}
	For each index $i$, every word in $C_i$ has the same length as $w$.
\end{lemma}
\begin{proof}
	This can be shown by a straightforward induction on $i$. It is true in $C_1$, since $C_1 = \{w\}$. So suppose every word in $C_i$ has length $|w|$, and let $xy$ be a new word in $C_{i+1}$ for some $x, y \in A^+$ such that $x$ or $y$ is in $W(C_i)$. Then either $xy$ or $yx$ is in $C_i$ and hence $|xy| = |yx| = |w|$ by the inductive hypothesis. Hence every word in $C_{i+1}$ has length $|w|$ and so every word in $C_i$ has length $|w|$, for any index $i$.
\end{proof}

It follows from the above that since $|C_i| \le |A|^{|w|}$ (which is finite since $M$ is finitely presented) and $C_{i+1} \supseteq C_i$ for all $i \ge 1$, there is a maximal set $C_k$. Define a new set $E(M)$ to be those words in $W(C_k)$ which have no proper right factors in $W(C_k)$.

This set $E(M)$ will effectively serve as the generating set in the presentation for the group of units of $M$ which we construct in the remainder of the proof.

\begin{example} \label{ex:Ck-group}
	Consider the monoid $M$ defined by the presentation $\langle b, c \mid bcb = \epsilon \rangle$. Running the procedure again we obtain:

	\begin{center}
	\renewcommand{\arraystretch}{1.2}
	\begin{tabular}{r|ll}
		$i$ & $C_i$ & $W(C_i)$ \\ \hline
		1 & $\{bcb\}$ & $\{b, bcb\}$ \\
		2 & $\{cbb, bbc, bcb\}$ & $\{cbb, c, b, bb, bc, cb, bbc, bcb\}$
	\end{tabular}
	\end{center}

	Notice that both generators $b$ and $c$ are in $W(C_2)$, so $C_2$ contains every cyclic permutation of $bcb$. Hence $C_k = C_2$ and so $E(M) = \{ b, c\}$. Since $E(M)$ is supposed to generate the group of units of $M$, this suggests (correctly) that every generator, and hence every element, of the monoid is invertible, i.e. that $M$ is in fact a group. 
\end{example}

\begin{example}
	Consider the bicyclic monoid, given by the presentation $B = \langle b, c \mid bc = \epsilon \rangle$.
	Applying the above construction, we find:

	\begin{center}
	\renewcommand{\arraystretch}{1.2}
	\begin{tabular}{r|ll}
		$i$ & $C_i$ & $W(C_i)$ \\ \hline
		1 & $\{bc\}$ & $\{bc\}$ \\
		2 & $\{bc\}$ & $\{bc\}$
	\end{tabular}
	\end{center}

	So $C_k = C_1 = \{ bc \}$, and hence $E(B) = \{bc\}$. This suggests that the only invertible element in $B$ is the identity $(bc)^n = bc = \epsilon$.
\end{example}

\begin{example} \label{ex:monoidN}
	For a less extreme example, look at the monoid $N$ from earlier with defining presentation $\langle a, b, c \mid bcab = \epsilon\rangle$. Performing the computations:

	\begin{center}
	\renewcommand{\arraystretch}{1.2}
	\begin{tabular}{r|ll}
		$i$ & $C_i$ & $W(C_i)$ \\ \hline
		1 & $\{bcab\}$ & $\{b, bcab\}$ \\
		2 & $\{bbca, cabb, bcab\}$ & $\{b, bb, bbca, ca, bcab, bca, cabb, cab\}$
	\end{tabular}
	\end{center}

	This gives $C_k = C_2 = \{bbca, cabb, bcab\}$ and hence $E(N) = \{b, ca\}$. Notice that in this case, as in our previous examples, the relator $bcab$ can be expressed as a product of the words in $E(N)$.

\end{example}

\subsubsection{An alternative definition}

In \cite{Zhang1992}, an alternative, non-constructive definition of a generating set for the group of units is given, based on the idea of \emph{minimal factors} of $w$.

\begin{defn}
	A word $v \in A^+$ is \dn{minimal} if:
	\begin{enumerate}[(i)]
		\item it is invertible in $M$,
		\item $|v| \le |w|$ and
		\item none of its nonempty prefixes are invertible in $M$.
	\end{enumerate}
\end{defn}

We can then write the relator $w$ in terms of minimal factors $w = w_1w_2\ldots w_n$.


\subsection{Defining the presentation}

Define a new alphabet $B$ disjoint with $A$ such that we have a bijection $\midtilde\phi \colon E(M) \to B$, and let $\phi \colon E(M)^* \to B^*$ be the unique homomorphic extension of $\midtilde\phi$ to $E(M)^*$. By the following result, $\phi(w)$ is well-defined:

\begin{prop} \label{lma:relator-factors-E(M)}
	The relator $w$ is a product of factors in $E(M)$.
\end{prop}
\begin{proof}
	\hspace{-0.25mm}We show by induction on word length that every element of $W(C_k)$ is a product of factors in $E(M)$. First suppose that $u \in W(C_k)$ is of minimal length in $W(C_k)$. Then $u$ has no proper factors in $W(C_k)$, and so $u \in E(M)$.

	Now suppose that all strings in $W(C_k)$ with length less than $n$ are products of factors in $E(M)$, and let $u \in W(C_k)$ have length $n$. If $u$ has no proper right factors in $W(C_k)$, then it is in $E(M)$ by definition. Otherwise, we can write $u = ve$ for $e \in E(M)$, $v \in A^+$.

	We want to show that $v \in W(C_k)$, so that by the inductive hypothesis (since $|v| < n$), $v \in E(M)^*$ and hence $u \in E(M)^*$. Since $v$ is a prefix of $u$, for $v$ to be in $W(C_k)$ it remains only to show that it is a suffix of some word in $C_k$. Because $u \in W(C_k)$, there is some word $x \in C_k$ such that $x = x'u = x've$ . Then by the definition of $C_{k+1}$, since $e \in W(C_k)$, the word $ex'v \in C_{k+1}$. But $C_{k+1} = C_k$, so $v$ is indeed a suffix of a word in $C_k$.

	Altogether, this means $u$ is a product of factors in $E(M)$ and so by induction all the words of $W(C_k)$ are such a product. In particular, since $w \in W(C_k)$, $w$ is a product of factors in $E(M)$.
\end{proof}

We now define a monoid $M'$ given by the presentation $\langle B \mid \phi(w) = \epsilon \rangle$. We assert that this monoid is in fact a group:

\begin{prop} \label{prop:M'-is-group}
	The monoid $M' = \langle B \mid \phi(w) = \epsilon\rangle$ is a group.
\end{prop}
\begin{proof}
	It suffices to show that every generator of $M'$ is invertible. We first show by induction that for all $i$, every word in $C_i$ is trivial in $M$. In the base case $C_1$, the only word to consider is $w$ itself, which is trivial by the defining relation $w = \epsilon$. Suppose then that all words in $C_j$ are trivial, for each $j \le i$, and consider a word $v \in C_{i+1}$, $v \not\in C_i$.

	This new word $v$ can arise in two ways. In the first case, $v = xy$ for some $y \in W(C_i)$, $yx \in C_i$. So by the inductive hypothesis, $yx =_M \epsilon$, i.e. $x$ is a right inverse for $y$ in $M$. As $y \in W(C_i)$, there is a word $u \in C_i$ such that $u = u'y =_M \epsilon$ for some $u' \in A^*$. So $u'$ is a left inverse for $y$ in $M$. We have a left and a right inverse for $y$ in $M$, so they must be equivalent in $M$, hence $v = xy =_M u'y =_M u$. But $u$ is in $C_i$ and so is trivial by the inductive hypothesis. Therefore $v =_M \epsilon$ as required.

	A similar argument shows that $v$ is trivial in $M$ if $v = yz$ for $y \in W(C_i)$, $zy \in C_i$. This accounts for every word in $C_{i+1}$, and so by induction all words in $C_j$ are trivial in $M$, for every index $j$. In particular, all the words in $C_k$ are trivial.

	For any word $z \in W(C_k)$, there are words $a, b$ in $C_k$ such that $a = za'$ and $b = b'z$ for some $a', b' \in A^*$. Since these words $a$ and $b$ are trivial in $M$, $a'$ is a right inverse for $z$ and $b'$ is a left inverse for $z$ in $M$ and hence $z$ is invertible in $M$. In particular, it follows that every word in $E(M)$ is invertible.

	To conclude, let $b \in B$ be a generator of $M'$. Then $\tilde\phi^{-1}(b) \in E(M)$ has an inverse $\midbar b$ in $M$. Hence $\epsilon =_M \tilde\phi^{-1}(b) \midbar{b}$ and so $\epsilon =_{M'} b\phi(\midbar{b})$; and likewise $\phi(\midbar{b})b = \epsilon$. The arbitrary generator $b$ of $M'$ is hence invertible, so $M'$ is a group.
\end{proof}

Let us apply these results to our monoid $N$ from \cref{ex:monoidN}. We calculated previously that $E(N) = \{b, ca\}$, so write $B = \{\alpha, \beta\}$ with the homomorphism $\phi$ taking $b \mapsto \alpha$ and $ca \mapsto \beta$. The resulting group $N'$ is then given by the monoid presentation $\langle \alpha, \beta \mid \alpha\beta\alpha = \epsilon \rangle$. This is isomorphic to the group we considered in \cref{ex:Ck-group}.

We assert further that these presentations, as suggested, give the group of units of $M$.

\begin{theorem}
	The monoid $M'$ is isomorphic to the group of units of $M$.
\end{theorem}

In light of this, we shall henceforth refer to the monoid $M'$ as $G$.

\subsection{The rewriting system}

Let $\prec$ be some linear order on the alphabet $A$, and extend it to a short-lex order $<$ on $A^*$. Then define a rewriting system $R$ on $A^*$ by
	\[ R = \{ (u, v) \mid u, v \in E(M)^*, v < u, \phi(u) =_G \phi(v) \}. \]

We note immediately that $R$ is noetherian: since if $(u, v)$ is a rule in $R$, then we must have $v < u$, and the short-lex order $<$ is a well-founded relation by a result from the previous section.

This system $R$ is equivalent to the system $\{(w, \epsilon)\}$, i.e. they present the same monoid:
\begin{lemma} \label{lma:R-equivalent-to-pres}
	The rewriting systems $\{(w, \epsilon)\}$ and $R$ are equivalent in the sense that their induced congruences  are equal, and hence that $\langle A \mid w \rangle$ = $\langle A \mid \{u = v : (u, v) \in R\}\rangle$.
\end{lemma}
\begin{proof}
	First, observe that $w \in E(M)^*$ by \cref{lma:relator-factors-E(M)}; $\epsilon < w$; and $\phi(w) =_G \epsilon$ follows immediately from the presentation for $G$, so $(w, \epsilon)$ is a rule in $R$ and hence $\leftrightarrow^*_{\{(w,\epsilon)\}}\ \subseteq\ \leftrightarrow^*_R$.

Conversely, suppose $(u, v)$ is a rule in $R$. Then $\phi(u) =_G \phi(v)$ means $\phi(u) \leftrightarrow^*_{\{(\phi(w), \epsilon)\}} \phi(v)$, and since $\phi$ is a homomorphism, $u \leftrightarrow^*_{\{(w, \epsilon)\}} v$. So $\leftrightarrow^*_R\ \subseteq\ \leftrightarrow^*_{\{(w,\epsilon)\}}$.

Hence the two rewriting systems are equivalent.
\end{proof}


\subsubsection{\texorpdfstring{Some lemmas on $E(M)$}{Some lemmas on E(M)}}

We state here two lemmas about the generating set $E(M)$ which will be useful to prove that $R$ is confluent:

\begin{lemma} \label{lma:no-middle-E(M)}
	If $x, y, z \in A^*$ are strings such that $xy, yz \in E(M)$, then either $y = \epsilon$ or $x = z = \epsilon$.
\end{lemma}
\begin{proof}
	Suppose $y \ne \epsilon$. Then since $xy \in E(M)$, $xy \in W(C_k)$ and in particular, $xy \in L(C_k)$, so there is some $\alpha \in A^*$ such that $\alpha x \cdot y \in C_k$. So $y$ is a right factor of a word in $C_k$, i.e. $y \in R(C_k)$. Likewise, $yz \in R(C_k)$ so $y \cdot z\beta \in C_k$ for some $\beta \in A^*$ and $y \in L(C_k)$. Hence $y \in W(C_k)$. By the definition of $E(M)$, $xy$ has no proper right factor in $W(C_k)$, so $y$ must not be a proper factor; but by assumption, $y \ne \epsilon$, so we must have $x = \epsilon$. Similarly, $yz$ has no proper right factor in $W(C_k)$, so $z$ is not a proper factor and $z = \epsilon$.
\end{proof}

\begin{cly} \label{cly:middle-E(M)*}
	If $x, y, z \in A^*$ are strings such that $xy, yz \in E(M)^*$, then $y \in E(M)^*$.
\end{cly}


\subsubsection{\texorpdfstring{Confluence of $R$}{Confluence of R}}

We apply \cref{thm:confluent-cond} directly to $R$ to show that it is locally confluent. Since $R$ is noetherian, by \cref{thm:newman} this suffices to show $R$ is confluent. Recall that \cref{thm:confluent-cond} states:

\begin{theorem*}
	A rewriting system $R$ over an alphabet $A$ is locally confluent if and only if the following hold for all strings $u, v, w, x, y \in A^*$:
	\begin{enumerate}[(1)]
		\item \label{it:conf-overlap} If $uv \to x$ and $vw \to y$ are rules of $R$ then there is a $z \in A^*$ such that $xw \to^*_R z$ and $uy \to^*_R z$.
		\item \label{it:conf-middle} If $uvw \to x$ and $v \to y$ are rules of $R$ then there is a $z \in A^*$ such that $x \to^*_R z$ and $uyw \to^*_R z$.
	\end{enumerate}
\end{theorem*}


For part \ref{it:conf-overlap}, suppose $uv \to_R x$ and $vw \to_R y$, with $uv \ne vw$ (if they are equal, we have nothing to prove). We claim that in fact one of $xw \to uy$ or $uy \to xw$ is a rule in $R$ and so $uy$ or $xw$ is a suitable $z$. By the definition of $R$, $uv, vw, x, y\in E(M)^*$, and so by \cref{cly:middle-E(M)*}, $v \in E(M)^*$. Hence $u, w \in E(M)^*$ and $uy, xw \in E(M)^*$. Now observe that by the rules we know are in $R$ and the fact $\phi$ is a homomorphism, we have $\phi(xw) = \phi(x)\phi(w) =_G \phi(uv)\phi(w) = \phi(u)\phi(vw) =_G \phi(u)\phi(y) = \phi(uy)$. Finally, since $<$ is linear, either $xw < uy$, in which case $uy \to xw$ is a rule in $R$; or $uy < xw$, in which case $xw \to uy$ is a rule in $R$ as required.

Now consider condition \ref{it:conf-middle}: suppose $uvw \to_R x$ and $v \to_R y$, and again assume that $v \ne y$. Observe that $\phi(x) =_G \phi(uyw)$, since $\phi(uvw) =_G \phi(x)$ and $\phi(v) =_G \phi(y)$. Furthermore, either $uyw < x$ or $x < uyw$. So as before, if $uyw \in E(M)^*$, then one of $x$ or $uyw$ will be a suitable $z$. Since $uvw, v, y \in E(M)^*$, if $uyw \not\in E(M)^*$, then $u = u_1u_2 \cdots u_m U$ and $w = W w_1 w_2 \cdots w_n$ for $u_i, w_i \in E(M)$ and some non-empty strings $U$ and $W$, with $UvW \in E(M)$. This means $v$ must be shorter than the longest word in $E(M)$ (or $UvW$ would be longer and therefore not in $E(M)$).

The following lemma completes the proof:

\begin{lemma} \label{lma:shorter-irreducible}
	Any word $a \in A^*$ shorter than the longest word in $E(M)$ is irreducible by $R$.
\end{lemma}
\begin{proof}
	Let $L$ be a word of maximal length in $E(M)$, and suppose $a$ were reducible. Then we can write $a = a'ba''$ where $b \in E(M)^*$ and $b \to_R c$ for some $c \in E(M)^*$. Then $c < b$ and so $|c| \le |b| \le |a| < |L|$, and hence $L$ cannot appear in $b$ or $c$.
	
	We then recall the Freiheitssatz for one-relator groups (\cref{thm:freiheitssatz}).	Since $b \to_R c$, $\phi(b) =_G \phi(c)$. Then as $L$ is not in $b$ or $c$, $\phi(L)$ is not in $\phi(b)$ or $\phi(c)$, i.e. $\phi(b)$ and $\phi(c)$ are in the subgroup of $G$ generated by $B \setminus \{\phi(L)\}$. This is free by the Freiheitssatz, and so $\phi(b) = \phi(c)$ as words. Since $\phi$ is a homomorphism and $\midtilde\phi$ is a bijection, $\phi$ is injective and so $b = c$. But $c < b$, so we have a contradiction and $a$ is indeed irreducible.
\end{proof}

It follows from this that $v$ is irreducible by $R$; but this is impossible, since by hypothesis $v \to_R y$. So in fact $uyw \in E(M)^*$, and one of $uyw \to_R x$ or $x \to_R uyw$ holds. Therefore condition \ref{it:conf-middle} is satisfied and $R$ is confluent.


\subsection{The word problem is decidable}

We can now prove \cref{thm:ors-decidablewp}. We essentially use the argument in \cref{sec:normal-forms} using our confluent, noetherian rewriting system $R$. For the rewriting algorithm (\cref{alg:rewrite}) to halt, we required that only a finite number of rules applied to any given word $u \in A^*$, and that there was a procedure which could enumerate this set in a finite number of steps.

Start by simply enumerating all pairs $(a, b)$ of strings of length $|u|$ or less. It is decidable to compare $a$ and $b$ under the short-lex order, i.e. to determine if $b < a$. Furthermore, by Magnus' theorem (\cref{thm:orgp-decidablewp}), it is decidable whether $a =_G b$. If and only if both of these hold is $a \to b$ a rule in $R$. There are a finite number of these pairs $(a, b)$, so we have our required procedure.

Given two words $u, v \in A^*$, we can thus obtain their normal forms $\bar u$ and $\bar v$ with respect to $R$ in a finite number of steps and, comparing these letter by letter, determine if $u =_R v$. Therefore it is decidable whether $u =_R v$.

The rewriting system $R$ is equivalent to $\{(w, \epsilon)\}$ by \cref{lma:R-equivalent-to-pres}, and since $\{(w, \epsilon)\}$ presents our monoid $M$, $u =_R v$ if and only $u =_M v$. This is precisely the word problem for $M$, and so we have shown that the word problem for a one-relator special monoid is decidable.


\printbibliography

\printindex

\end{document}
