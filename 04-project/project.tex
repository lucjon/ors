\documentclass[noindex,noinsetproof,emphthm,12pt]{lmaths}
\synctex=1
\addbibresource{../ors.bib}
\ExecuteBibliographyOptions{url=false}

\geometry{vmargin=2.5cm}
\usepackage{booktabs}
\usepackage{tikz}
\usepackage{minted}
\usepackage{pdfpages}
\usetikzlibrary{arrows}
\usetikzlibrary{cd}
\usetikzlibrary{positioning}
\tikzcdset{arrow style=math font}

\setlist{leftmargin=3em}

\let\oldbeginabstract\abstract
\renewcommand{\abstract}{\oldbeginabstract\noindent}

\newcommand{\draftnote}[1]{\textcolor{red}{#1}}
\newcommand{\nearrowstar}{\mathclap{\nearrow}_{*}}
\newcommand{\searrowstar}{\mathclap{\searrow}^{*}}
\newcommand{\leftrightst}{\mathrel{\smash{\stackrel{\hspace{0.1em}\ast}{\leftrightarrow}}}}
\newcommand{\paradec}{\par\begin{center}$\ast$\end{center}}
\newcommand{\Abar}{\widebar{A}}

\newcommand{\frontmatter}{\pagenumbering{roman}}
\newcommand{\mainmatter}{\pagenumbering{arabic}}
\let\oldappendix\appendix\renewcommand{\appendix}{\oldappendix\clearpage}

\newtheorem{algorithm}[defn]{Algorithm}

\usepackage{fancyhdr}
\setlength\headheight{15pt}
\pagestyle{fancy}
\fancyhead{}
\lhead{\itshape\rightmark}
\renewcommand\sectionmark[1]{\markboth{\thesection. #1}{}}

\DeclareMathOperator{\WP}{WP}
\DeclareMathOperator{\FG}{FG}
\DeclareMathOperator{\FGamma}{F\Gamma}
\DeclareMathOperator{\MT}{MT}
\DeclareMathOperator{\BS}{BS}

\hideregion{computing}

\title{Understanding One-Relation Semigroups using Rewriting Systems}
\author{Lucas Jones}

\begin{document}
\vfill
\maketitle
\vfill
\thispagestyle{empty}
\clearpage

\frontmatter

\clearpage
I certify that this project report has been written by me, is a record of work carried out by me, and is essentially different from work undertaken for any other purpose or assessment.

\vspace{1.5em}
Signed: \rule[-2pt]{15em}{1pt} \\*[0.8em]
\hphantom{Signed: }Lucas Jones
\clearpage


\begin{abstract}
	In this project, we discuss a long-standing area of research in semigroup theory --- the question of the decidability of the word problem for a semigroup --- and its connections with the theory of string rewriting systems. In particular, we examine the open problem of the word problem for semigroups admitting a presentation with one defining relation. We present a proof that a significant special case --- the word problem for so-called `special' one-relation monoids --- is solvable, using an approach due to Zhang, and prove some results about the structure of these monoids. We also explore the connection between this work and the work of Ivanov et al. on special inverse monoids, which describes a potential avenue for solving the word problem for all one-relation semigroups.
\end{abstract}
\clearpage

\tableofcontents

\clearpage

\mainmatter
\section{Introduction} \label{sec:intro}

The aim of this project is to investigate the decidability of the word problem for so-called special one-relation monoids, via Zhang's application of string rewriting systems. In \cref{sec:intro}, we will recall some elementary definitions which will be useful throughout the project, before giving a brief history of the word problem for semigroups and, in particular, an overview of work which has been done for the special case of one-relator semigroups.

In \cref{sec:rewriting-systems}, we provide an elementary introduction to string rewriting systems and their properties, which is crucial to \cref{sec:special-monoids}, an exposition of Zhang's proof in \cite{Zhang1992a} that the word problem for one-relation special monoids is decidable. \Cref{sec:structure} extends these rewriting methods according to \cite{Zhang1992}, using them to prove various, perhaps surprising, results on the unit structure of one-relation special monoids.

The conclusion of the project, in \cref{sec:inverse-monoids}, discusses the broader context of Zhang's work in relation to the broader one-relation semigroup problem, and gives an overview of an intriguing analogy to Ivanov, Margolis and Meakin's work in \cite{Ivanov2001} on one-relation special inverse monoids which could lead to a solution to the general one-relation word problem.

It is expected that the reader has a basic familiarity with the theory of semigroups, equivalent to the St Andrews module \emph{MT5826 Semigroups}, and an elementary acquaintance with groups.

\subsection*{Acknowledgements}
I would like to acknowledge foremost the generous supervision and support of Prof Nik Ru≈°kuc throughout the project. I would also like to thank Gerard O'Reilly for providing much helpful input and for joining Bea Adam-Day, Bea Hill and Sam Traynor in many hours' entertaining mathematical discussion over the years.

\subsection{Free semigroups, monoids and groups}

An \dn{alphabet} is any finite set. The \dn{free semigroup} over this alphabet, denoted $A^{+}$, is the set of all nonempty finite strings made up of letters from $A$, equipped with the operation of concatenation.

The \dn{free monoid} $A^*$ over $A$ is the set $A^+ \cup \{\epsilon\}$ under concatenation, where $\epsilon$ is the empty string. A \dn{language} (over $A$) is any subset of $A^*$.

The construction of a free group is more involved, since the existence of inverses forces there to be some relations between letters. Again, let $A$ be an alphabet and fix an arbitrary set $A^{-1}$ which is disjoint but in bijection with $A$. We will write $a^{-1}$ for the image of $a \in A$ under this bijection. For any letter $a \in A$, the strings $aa^{-1}$ and $a^{-1}a$ are known as \dn{trivial relators}. We say a word is \dn{freely reduced} if it contains no trivial relators.

We say that two words $u$ and $v$ in $(A \cup A^{-1})^*$ are related by an elementary move if one can transform $u$ into $v$ by adding or removing a trivial relator at some point in $u$. We extend this to an equivalence relation $\sim$ by saying that $u \sim v$ if $u$ is related to $v$ by a finite sequence of elementary moves.  Furthermore, we claim that this relation $\sim$ is a congruence, and that the resultant quotient monoid $(A \cup A^{-1})^*/{\sim}$ is a group, called the \dn{free group} on $A$ and denoted $\FG(A)$.

\subsection{Presentations}

Presentations are a concise way of defining a semigroup, monoid or group in terms of a set of generators and a set of relations between these generating elements.

\begin{defn}
	A \dn{presentation} is an alphabet $A$ together with a set of `relations' $R \subseteq A^+ \times A^+$. Normally this is written $\langle A \mid R\rangle$, or $\langle A \mid a_1 = b_1, a_2 = b_2, \cdots \rangle$, if $R = \{(a_1, b_1), (a_2, b_2), \ldots\}$.
\end{defn}

The idea is that the letters in $A$ generate a semigroup (or monoid, or group) and we want the relations in $R$ and their consequences to be the only equations which are true in the semigroup. In a sense, the semigroup (or monoid, or group) presented by a presentation is the `largest' semigroup in which these equations are true.

\begin{defn}
	If $\langle A \mid R \rangle$ is a presentation, the \dn{semigroup presented by} $\langle A \mid R\rangle$ is quotient semigroup $A^+/\rho$, where $\rho$ is the smallest congruence on $A^+$ containing $R$. This is also denoted $\langle A \mid R \rangle$.
\end{defn}

For example, the free semigroup on two letters $F_2$ is presented by $\langle a, b \mid \rangle$. As another example, the presentation $\langle a \mid a^7 = a \rangle$ defines the cyclic group of order 6.

If $S$ is a semigroup given by a presentation, we will write $\rho_S$ for this smallest congruence by which we are taking the quotient.

This definition extends very naturally to monoids.

\begin{defn}
	The \dn{monoid presented by a presentation} $\langle A \mid R\rangle$ is the quotient monoid $\Mon \langle A \mid R\rangle = A^*/\rho$, where $\rho$ is the smallest congruence on $A^*$ containing $R$. This is also denoted $\langle A \mid R \rangle$.
\end{defn}

\begin{example}
The bicyclic monoid, can be written as $\Mon \langle b, c \mid bc = \epsilon \rangle$. This is equivalent to the semigroup presentation $\langle b, c, \epsilon \mid bc = \epsilon, b\epsilon = \epsilon b = b, a\epsilon = \epsilon a = a, \epsilon^2 = \epsilon \rangle$.
\end{example}

\begin{example}
	The symmetric group on three points, $S_3$, is given by the semigroup presentation $\langle \sigma, \tau \mid \sigma^2 = \tau^2 = (\sigma\tau)^3 = \epsilon \rangle$, where the generators $\sigma$ and $\tau$ are the 2-cycles $\sigma = (1\ 2)$ and $\tau = (2\ 3)$.
\end{example}

A group presentation is defined in a similar way to the above, except that we need to include the trivial relations $aa^{-1} = a^{-1}a = \epsilon$ implied by the group axioms.

\begin{defn}
	The \dn{group presented by a presentation} $\langle A \mid R\rangle$, is the quotient monoid $\Gp \langle A \mid R\rangle = A^*/\rho$, where $\rho$ is the smallest congruence on $A^*$ containing $R$ and the trivial relations, namely $aa^{-1} = \epsilon$ and $a^{-1}a = \epsilon$ for each $a \in A$.
\end{defn}

To give a final example, the dihedral group of order 6 is given by the presentation $\Gp \langle \rho, \sigma \mid \rho^3 = \epsilon, \sigma^2 = \epsilon, \sigma\rho = \rho\sigma^{-1} \rangle$, with $\rho$ representing the rotation by $\frac{2\pi}{3}$ radians and $\sigma$ representing a horizontal flip.

In this project, we will be interested mostly in \dn{finitely presented} semigroups, monoids and groups; that is, those structures which admit a presentation $\langle A \mid R\rangle$ where both $A$ and $R$ are finite. Not every semigroup is finitely presented, however. In particular, $\langle a, b \mid ab^ia = aba \quad\forall i \in \mathbb{N} \rangle$ defines a semigroup which is not finitely presented.


\subsection{Decidable and undecidable problems}

%In the 1930s, the discovery that several natural models of computation (such as Turing machines and Church's $\lambda$-calculus among others) were equally powerful provided strong motivation for most mathematicians to accept that for a procedure to be able to be solved by an algorithm meant that it could be solved by, for example, a Turing machine. With a concrete definition of computability came problems which were proven not to be computable. Turing described his machines for the first time in the 1936 paper \emph{On computable numbers with an application to the \emph{Entscheidungsproblem}}, which he used to prove the existence of these undecidable problems. He showed that the so-called halting problem was undecidable.

Fix an alphabet $A$ and let $L$ be a language over $A$. Then the \dn{decision problem} for $L$ takes as input a word $w$ in $A^*$ and outputs `true' if $w$ belongs in $L$ and `false' if it does not. A decision problem is said to be \dn{decidable} if there is an algorithm which always answers true or false in a finite number of steps, no matter what word $w$ is given as input, or \dn{undecidable} if no such algorithm exists.

One famous decision problem, which motivated much study in the early 20th century, is the \emph{Entscheidungsproblem} posed by Hilbert in the 1920s. Roughly speaking, the language $L$ in this case is the set of logical statements, described in terms of an appropriate alphabet, which are true assuming some set of axioms. Hilbert's challenge was to find an algorithm to solve this decision problem.

Church and Turing proved (independently) in the 1930s that it is not. However, to do so, they had to formalise the notion of `algorithm'. The intuitive concept of an algorithm has, of course, existed for thousands of years --- however, in order to prove that none exists for a particular problem, a mathematically rigorous definition is required. Until this was available, questions such as Hilbert's, as well as some about groups and semigroups which we will discuss in \hyperref[sec:word-problem]{the next section}, could not be answered negatively. The word problem for a group was defined some time before this, but the only results concerning it were algorithms to solve it for particular classes of groups. It was only afterwards that it could be proven that the word problem is undecidable in general, for example. 

A more elementary example of an undecidable problem is the \dn{halting problem}. As input, it takes a description of an algorithm and an input word $w$. In return, it outputs `true' if the algorithm completes in a finite number of steps --- or \dn{halts} --- given the input $w$, and `false' if it runs indefinitely.

\begin{theorem}
	The halting problem is undecidable.
\end{theorem}
\begin{proof}
	Suppose the halting problem were decidable, so that there exists an algorithm $H(A, X)$ which returns in finite time whether or not the algorithm $A$ halts given input $X$. Define a new algorithm $S(A)$, as follows: 
	\begin{enumerate}	
		\item Compute $H(A, A)$, i.e. whether the algorithm $A$ halts given a description of $A$ as input.
		\item If $A$ does halt on input $A$, loop forever.
		\item Otherwise, output `true' and halt.
	\end{enumerate}

	Now consider the result of applying $S$ to a description of itself. If $S$ halts on $S$, then by definition $H(S, S)$ must have been false. But this means that $S$ does not halt on input $S$, which is a contradiction. On the other hand, by assumption, our algorithm $H$ never halts. So if $S$ does not halt on $S$, $H(S, S)$ must be false --- but this is also a contradiction! So such an algorithm $H$ can not exist.
\end{proof}


\subsection{The word problem for groups} \label{sec:word-problem}

The word problem is one of three fundamental decision problems associated with a group introduced by Dehn \cite{Dehn1911} in 1911, the others being the conjugacy problem and the isomorphism problem.

\begin{defn}
	Let $G = \Gp \langle A \mid R \rangle$ be a group. Then the \dn{word problem} for $G$, denoted $\WP(G)$, is the set
	\[ \WP(G) = \{ (u, v) \mid u, v \in A^*, u =_G v \} \]
	of pairs of words in the generators $A$ which are equal in $G$. The \dn{conjugacy problem} for $G$ is the set
	\[ \{ (u, v) \mid u, v \in A^*, \exists\ w \in G \colon u = w^{-1}vw \} \]
	of pairs of words which represent conjugate elements.
\end{defn}

The isomorphism problem is slightly different: it asks, given two presentations $\langle A \mid R \rangle$ and $\langle B \mid S \rangle$, whether the groups they present are isomorphic.

Each of these problems is readily generalisable to finitely presented semigroups. Axel Thue discussed the word problem for semigroups as early as 1914; interestingly, by considering what we would now call rewriting systems (as we will in \cref{sec:rewriting-systems}) rather than semigroups as algebraic structures\footnote{In \cite{Thue1914}; see the translation and commentary in \cite{Power2013}.}.

The word problem is readily solvable for certain classes of groups. For example, if $G$ is a free group, the algorithm is as follows: suppose $G$ is freely generated by a set $A$, and suppose that we have two elements $u$ and $v$ of $G$, written as words in $A$ and the corresponding inverse letters. Then since there are no relations in the group except those that follow from the group axioms, namely $aa^{-1} = a^{-1}a = \epsilon$ for each $a \in A$, we can iterate through the string, removing all of these pairs. Then $u =_G v$ if and only if these `reduced' words are equal, letter for letter.

In 1947, however, Emil Post proved \cite{Post1947} that the general word problem for finitely-presented semigroups is undecidable; and shortly afterwards, in 1950, Turing himself showed \cite{Turing1950} that the word problem for cancellative finitely-presented semigroups is undecidable. The 1950s also saw Novikov \cite{Novikov1955} and Boone \cite{Boone1959} independently prove that the word problem for a general finitely-generated group is undecidable.

Some important classes of groups and semigroups do, however, have decidable word problems. All finite groups and semigroups have decidable word problem, for example. The special case which we shall be most concerned with in this project is that of the word problem of one-relation groups and semigroups.

\subsection{One-relation groups and semigroups} \label{sec:one-relation-overview}

A one-relation group or semigroup is a finitely presented group or semigroup which admits a presentation of the form $\langle A \mid u = v\rangle$, where $u$ and $v$ are words in $A^*$. The word problem for one-relator groups was in fact solved by Magnus in the early 1930s.

\begin{theorem}[Magnus \cite{Magnus1932}, 1932] \label{thm:orgp-decidablewp}
	Let $G$ be a group admitting a presentation of the form $\langle A \mid u = v\rangle$, where $u$ and $v$ are words over the generating set $A$. Then the word problem for $G$ is decidable.
\end{theorem}

In his proof, Magnus relies heavily on the following result on the structure of one-relator groups, known as the \emph{Freiheitssatz}, which he proved a few years earlier in \cite{Magnus1930}:

\begin{theorem}[Freiheitssatz] \label{thm:freiheitssatz}
	Let $G = \Gp \langle A \mid w = \epsilon \rangle$ be a one-relator group, with $w$ cyclically reduced, and let $a \in A$ be a letter contained in $w$. Then the subgroup $\langle A \setminus \{a\} \rangle$ is a free group.
\end{theorem}

Here, a word is said to be \dn{cyclically reduced} if all cyclic permutations of it are freely reduced --- e.g. $aba^{-1}$ is freely reduced but not cyclically reduced, since $a^{-1}ab$ is a cyclic permutation containing the trivial relator $a^{-1}a$. Modern proofs of the above theorems can be found in \cite{Lyndon2001}.

While the word problem for one-relator groups is in a sense completely solved, it is currently an open problem as to whether the word problem for one-relator semigroups is decidable. In this project, we consider a significant special case first proved by Adjan in the 1960s \cite{Adian1966}:

\begin{defn}
We say a one-relator monoid is \dn{special} if it admits a finite presentation of the form $\langle A \mid r = \epsilon \rangle$.
\end{defn}

\begin{theorem}[Adjan]
	Let $M$ be a one-relator special monoid. Then $M$ has decidable word problem.
\end{theorem}

There is a monoid analogue to the Freiheitssatz, due to Squier and Wrathall (\cite{Squier1983}):
% XXX check this XXX
\begin{theorem}[Freiheitssatz for one-relator monoids]
	Let $S = \langle A \mid u = v \rangle$ be a one-relator group, with $w$ cylically reduced, and let $a \in A$ be a letter contained in $uv$. Then the subgroup $\langle A \setminus \{a\} \rangle$ is free.
\end{theorem}
However, perhaps surprisingly, while both Zhang's proof and Adjan's original proof of the result for one-relator special monoids rely crucially upon the Freiheitssatz for groups, neither uses the monoid result at all.


\section{Rewriting systems} \label{sec:rewriting-systems}

\subsection{Introduction}

A \dn{string rewriting system} over an alphabet $A$ is a set $R \subseteq A^* \times A^*$ of rules, normally written $\{u_1 \to v_1, u_2 \to v_2, \ldots\}$. The rules specify the action of the rewriting system on a string: each rule $u \to v$ specifies that whenever $u$ appears as a substring, it should be replaced by the string $v$. Formally:

\begin{defn}
	Let $R$ be a string rewriting system over an alphabet $A$. Then the \dn{rewriting relation} $\to_R$ (or often just $\to$) is defined as follows: if $u, v \in A^*$, then $u \to_R v$ if and only if there exist strings $A, B \in A^*$ and a rule $(w, z) \in R$ such that $u = AwB$ and $v = AzB$.
\end{defn}

\begin{example} \label{ex:rws1}
	Let $R$ be the rewriting system $\{ bb \to a, aa \to b \}$. Then $abba \to aaa$, $aaa \to ba$ and $aaa \to ab$. On the other hand, $a \nrightarrow bb$, $bba \nrightarrow ba$ and $abba \nrightarrow ab$.
\end{example}

Two strings are related under this relation if the right hand side is the result of making exactly one replacement according to a single rule in the corresponding rewriting system. Often it is useful to consider strings arising after an arbitrary number of replacements:

\begin{defn}
	The \dn{transitive closure} of the rewriting relation $\to_R$, denoted $\to_R^*$, is the smallest transitive relation on $A^*$ containing $\to_R$. Equivalently, two strings $u, v \in A^*$ are related under $\to_R^*$ if there exist strings $u_1, u_2, \ldots, u_n \in A^*$ (for some $n \ge 0$) such that $u \to_R u_1 \to_R u_2 \to_R \cdots \to_R u_n \to_R v$.
\end{defn}

Continuing \cref{ex:rws1}, while $abba \nrightarrow ab$, it is true that $abba \to^* ab$.

Let $u, v, w \in A^*$ be strings. If $u \to^* w$, then we say that $v$ is a \dn{descendant} of $u$. Furthermore, if it is also true that $v \to^* w$, then we say that $w$ is a \dn{common descendant} of $u$ and $v$. Whether or not a given string has a descendant is an important question when we are considering the termination properties of a string rewriting system. In particular, the `irreducible' strings are crucial:

\begin{defn}
	A word $u$ is \dn{irreducible} if it has no descendants; i.e. if there is no word $v$ such that $u \to v$.
\end{defn}

\subsection{Equivalences and presentations}

We can further extend the rewriting relation to an equivalence relation.

\begin{defn}
	The \dn{symmetric closure} of the rewriting relation $\to_R$, denoted $\leftrightarrow_R$, is defined such that for two words $u, v \in A^*$, $u \leftrightarrow_R v$ if and only if $u \to_R v$ or $v \to_R u$.
\end{defn}

\begin{defn}
	Given a string rewriting system $R$, the relation \dn{equivalence modulo $R$}, denoted $=_R$, is the smallest equivalence relation containing $R^*$. Equivalently, if $u, v \in A^*$ are two words, then $u =_R v$ if there exist strings $u_1, u_2, \ldots, u_n \in A^*$, for some $n \ge 1$, such that $u = u \leftrightarrow u_1 \leftrightarrow u_2 \leftrightarrow \cdots \leftrightarrow u_n = v$.
\end{defn}

In the above definition, taking $n = 1$ leaves no conditions to check, so $u =_R u$ for all strings $u \in A^*$.

\label{sec:rws-presentations} The usefulness of this equivalence relation for our purposes becomes apparent when we identify rewriting systems with monoid presentations. Suppose we have a presentation $\Mon \langle A \mid R\rangle$. Then picking a `direction' for each equation in $R$, we can write $R = \{ (r_1, s_1), (r_2, s_2), \ldots \}$. This set $R$ also forms a string rewriting system over $A^*$, and the equivalence $=_R$ is exactly the word problem for the monoid $M = \Mon \langle A \mid R\rangle$. Furthermore, $=_R$ is also a congruence on $A^*$, and the quotient $A^*/{=_R}$ is isomorphic to $M$.

\subsection{Noetherian rewriting systems}

Noetherianness is one property we put on a rewriting system to ensure its rewriting algorithm (see \ref{sec:normal-forms}) always terminates, no matter which string it is applied to. It is very useful to know that a rewriting system is noetherian if one wants to prove, as we will later, that an algorithm which uses it also always terminates. Before discussing noetherianness, we need to make some definitions relating to partial orders.

\begin{defn}
	A linear order on a set $X$ is a relation $<$ on $X$ which has the following properties for all $a, b, c \in X$:
	\begin{itemize}
		\item \emph{Trichotomy:} exactly one of $a < b$, $b < a$ or $a = b$ holds.
		\item \emph{Transitivity:} if $a < b$ and $b < c$, then $a < c$.
	\end{itemize}
\end{defn}

\begin{defn}
	An order $<$ on a set $X$ is \dn{well-founded} if there is no sequence $x_1, x_2, \ldots \in X$ such that
	\[ x_1 < x_2 < x_3 < \cdots. \]
\end{defn}

An interesting application of well-foundedness is the concept of noetherian induction, which generalises regular mathematical induction to any set equipped with a well-founded order.

\begin{prop}[Noetherian induction] \label{prop:noetherian-induction}
	Let $P(x)$ be a property of elements of a set $X$, and suppose that $\rightarrow$ is a well-founded order on $X$. Then $P(x)$ is true for all $x \in X$ if for any $y \in X$, $P(y)$ is true if $P(z)$ is true for all $z \ne y$ such that $y \rightarrow^* z$. That is, if $P(y)$ is true whenever $P$ is true for every descendant of $y$.
\end{prop}
\begin{proof}
	Suppose that for each $y \in X$, $P(y)$ is true if $P(z)$ is true for all descendants $z$ of $y$, and suppose there is some $x \in X$ such that $P(x)$ is false. If $x$ has no descendants, then $P(x)$ is vacuously true. So $x$ must have a descendant $x_2$ such that $P(x_2)$ is false. By the same reasoning $x_2$ must have a descendant $x_3$ such that $P(x_3)$ is false. Continuing in this fashion, we have an infinite chain of descendants
		\[ \cdots \to x_3 \to x_2 \to x, \]
	for each of which $P$ is false. But this contradicts $\to$ being well-founded, since by definition a well-founded relation has no infinite chains.
\end{proof}

The usual notion of induction on the natural numbers is the same as the above if $\mathbb{N}$ is equipped with its natural order, which is clearly well-founded.

We can now define the notion of a noetherian rewriting system in terms of its reduction relation.

\begin{defn}
	A noetherian rewriting system is a rewriting system whose reduction relation $\rightarrow$ is well-founded.
\end{defn}

The crucial consequence of this is the following:

\begin{prop}
	In a noetherian rewriting system, every string has an irreducible descendant. \label{prop:noetherian-every-irred}
\end{prop}
\begin{proof}
	Suppose $R$ is a noetherian rewriting system, and that $u \in A^*$ does not have an irreducible descendant. Then it must have some descendant $u_1 \in A^*$ such that $u \to u_1$, or $u$ itself would be irreducible. But $u_1$ must also have no irreducible descendants, since any of its irreducible descendants would also be irreducible descendants of $u$. Applying this reasoning to $u_1$, there must be a word $u_2 \in A^*$ such that $u_1 \to u_2$ and $u_2$ has no irreducible descendants. Continuing in this manner, we have a sequence of strings
		\[ u_1 \to u_2 \to u_3 \to \cdots; \]
	but since $R$ is noetherian, $\to$ is well-founded and so this is a contradiction.
\end{proof}

One way of showing a rewriting system is noetherian is to define a well-founded linear order $>$ on the set of strings $A^*$, and show that whenever $(u, v)$ is a rule in $R$, $u > v$. One common order which can be applied to many practical rewriting systems is the short-lexicographic order, which takes an order $\succ$ on the alphabet $A$ and extends it to a useful order on the whole set of strings $A^*$. Our examples thus far have mostly used the alphabet $\{a, b, c\}$, on which there is an `obvious' order to extend, $c \succ b \succ a$.

\begin{defn}
	Let $A$ be an alphabet, and let $\succ$ be a linear order on $A$. Then the \dn{short-lexicographic}, or \dn{short-lex order} $>$ on $A^*$ extending $\succ$ is defined as follows: suppose $u = u_1\cdots u_m, v = v_1\cdots v_n \in A^*$ are words. Then $u > v$ if and only if
	\begin{enumerate}[(i)]
		\item $m > n$; or
		\item $m = n$ and there exists an index $1 \le i \le n$ such that $u_j = v_j$ for all $1 \le j > i$ and $u_i \succ v_i$.
	\end{enumerate}
\end{defn}

It remains to show that the order as defined is suitable for the purposes we described above:
\begin{lemma}
	The short-lexicographic order is, in fact, a linear order.
\end{lemma}
\begin{proof}
	Let $A$ be an alphabet equipped with a linear order $\succ$ and let $>$ be the short-lex order extending $\succ$. Suppose $a, b, c \in A^*$, and assume that $|a| \ge |b| \ge |c|$. To show $>$ satisfies the trichotomy condition, we show that if $a \ne b$, one of $a > b$ or $b > a$ holds. If $a \ne b$, then either $a$ and $b$ have different lengths --- in which case $a > b$ --- or $|a| = |b|$ but they differ in at least one symbol. Let $i$ be the lowest $i \in \mathbb{N}$ such that $a_i \ne b_i$. Then since $\succ$ is a linear order, either $a_i \succ b_i$, in which case $a > b$; or $b_i \succ a_i$, in which case $b > a$. So the condition is satisfied.

	Finally, we show that $>$ is transitive. Suppose $a > b$ and $b > c$. If either $|a| > |b|$ or $|a| > |c|$, then $a > c$ follows immediately. So suppose $|a| = |b| = |c|$. Then since $a > b$, there is a lowest index $i \in \mathbb{N}$ such that $a_i \succ b_i$. Furthermore, since $b > c$, we must have $b_i = c_i$ or $b_i \succ c_i$. In either situation, $a_i \succ c_i$; and $a_1\cdots a_{i-1} = b_1\cdots b_{i-1} = c_1\cdots c_{i-1}$, so $a > c$ as required.

	Hence $>$ is indeed a linear order on $A^*$.
\end{proof}

\begin{prop}
	The short-lexicographic order is well-founded.
\end{prop}
\begin{proof}
	Let $A$ be an alphabet with a linear order $\succ$ extended to a short-lex order $>$ on $A^*$. Suppose we have an an infinite chain of words $u_1, u_2, \ldots \in A^*$ such that $u_1 > u_2 > \cdots$. Since the order $>$ on $\mathbb{N}$ is well-founded, the sequence $|u_1|, |u_2|, \ldots$ must eventually become constant, say at $|u_k|$. Then $|u_k| = |u_{k+1}| = |u_{k+2}| = \cdots$, so for $u_k > u_{k+1}$ to be true, the strings must differ at some index $i_1$. Then for $u_k > u_{k+1} > u_{k+2}$ to be true, $u_{k+1}$ and $u_{k+2}$ must differ at some index $i_2 \ge i_1$.
	
	Continuing for $u_{k+3}$ and so on, we obtain a nondecreasing sequence $i_1, i_2, \ldots$ of these indices. A particular index can only be repeated at most $|A|$ times, or we run out of letters in the alphabet which can be greater than the one in the corresponding place in the previous string. But the indices are bounded by $|u_k|$, so such an (infinite) sequence can not exist, and so neither can the words $u_1 > u_2 > \cdots$.
\end{proof}

\subsection{Confluence}

While noetherianness is useful in showing the rewriting algorithm terminates, for the answer it produces to be useful as a normal form, we want the resulting irreducible descendant to be unique. Without imposing extra conditions, it is possible that one string could have multiple irreducible descendants depending on which rules were chosen at each stage.

\begin{example}
	A very simple example of a non-confluent rewriting system is
		\[ R = \{ ab \to a, ab \to b \}. \]
\end{example}

\begin{defn}
	A rewriting system $R$ over an alphabet $A$ is \dn{confluent} if for all strings $a, b, c \in A^*$, whenever $a \to_R^* b$ and $a \to_R^* c$, there exists a string $z \in A^*$ such that $b \to^*_R z$ and $c \to^*_R z$.
\end{defn}

\begin{defn}
	A rewriting system $R$ over an alphabet $A$ is \dn{locally confluent} if for all strings $a, b, c \in A^*$, whenever $a \to_R b$ and $a \to_R c$, there exists a string $z \in A^*$ such that $b \to^*_R z$ and $c \to^*_R z$.
\end{defn}

\begin{theorem}[Newman] \label{thm:newman}
	If $R$ is a noetherian rewriting system, then $R$ is confluent if and only if it is locally confluent.
\end{theorem}

This theorem is often known as Newman's lemma, having first been proven by Newman in \cite{Newman1942}. Here we follow a simpler proof due to Huet written using the modern language of rewriting systems, which appears in \cite{Huet1980}. The principal technique of this proof is the notion of Noetherian induction (\cref{prop:noetherian-induction}).

\begin{proof}[ \pCref{thm:newman}]
	It is clear that a confluent system is locally confluent, since if $x \to z$ then $x \to^* z$ for all $x, z \in A^*$.

	Conversely, suppose $R$ is a locally confluent rewriting system over an alphabet $A$. We shall prove the statement $P(x)$ over $A^*$ by noetherian induction, defining $P(x)$ to be true if and only if for all $X, X' \in A^*$ such that $x \to^* X$ and $x \to^* X'$, there exists $z \in A^*$ such that $X \to^* z$ and $X' \to^* z$. If $P(x)$ holds for all strings $x$, the system is confluent by definition. 

	Let $x \in A^*$ be such that $P(x)$ holds for all its descendants. Let $X, X' \in A^*$ be such that $x \to_R^* X$ and $x \to_R^* X'$. In particular, because $\to$ is noetherian, there exist finite derivations $x = x_1 \to_R x_2 \to_R \cdots \to_R x_m = X$ and $x = x_1' \to_R x_2' \to_R \cdots \to_R x_n' = X'$. Since $R$ is locally confluent, the fact that $x \to_R x_1$ and $x \to_R x_1'$ means there exists a string $u \in A^*$ such that $x_1 \to_R^* u$ and $x_1' \to_R^* u$:

	{\centering
	\begin{tikzcd}
		& \arrow[dl] x \arrow[dr] \\
		x_1 \arrow[dd, "*"'] \arrow[dr, "*"] & & x_1' \arrow[dd, "*"] \arrow[dl, "*"'] \\
		& u & \\
		X & & X'
	\end{tikzcd}
	\par}

	Since $x_1$ is a descendant of $x$, by the inductive hypothesis, there exists a $v \in A^*$ such that $u \to^* v$ and $X \to^* v$.

	{\centering
	\begin{tikzcd}
		& \arrow[dl] x \arrow[dr] \\
		x_1 \arrow[dd, "*"'] \arrow[dr, "*"] & & x_1' \arrow[dd, "*"] \arrow[dl, "*"'] \\
		& u \arrow[ddl, "*", red] & \\
		X \arrow[d, "*"', red] & & X' \\
		v
	\end{tikzcd}
	\par}

	Next, since $x_1'$ is a descendant of $x$, by the inductive hypothesis there is a string $w \in A^*$ such that $u \to^* w$ and $X' \to^* w$.

	{\centering
	\begin{tikzcd}
		& \arrow[dl] x \arrow[dr] \\
		x_1 \arrow[dd, "*"'] \arrow[dr, "*"] & & x_1' \arrow[dd, "*"] \arrow[dl, "*"'] \\
		& u \arrow[ddl, "*"] \arrow[ddr, "*"', red] & \\
		X \arrow[d, "*"'] & & X' \arrow[d, "*", red] \\
		v & & w
	\end{tikzcd}
	\par}

	To complete the proof, we observe that $u$ is a descendant of $x$, so there is a string $z \in A^*$ such that $v \to^* z$ and $w \to^* z$.

	{\centering
	\begin{tikzcd}
		& \arrow[dl] x \arrow[dr] \\
		x_1 \arrow[dd, "*"'] \arrow[dr, "*"] & & x_1' \arrow[dd, "*"] \arrow[dl, "*"'] \\
		& u \arrow[ddl, "*"] \arrow[ddr, "*"'] & \\
		X \arrow[d, "*"'] & & X' \arrow[d, "*"] \\
		v \arrow[dr, "*", red] & & w \arrow[dl, "*"', red] \\
		& z & 
	\end{tikzcd}
	\par}

	Thus we have found a $z$ such that $x_1 \to^* z$ and $x_1' \to^* z$ as required.
\end{proof}

In order to show that a rewriting system is confluent, we can use the following condition, a restatement of theorem 1 given without proof in \cite{McNaughton1987}:
\begin{theorem} \label{thm:confluent-cond}
	A rewriting system $R$ over an alphabet $A$ is locally confluent if and only if the following hold for all strings $u, v, w, x, y \in A^*$:
	\begin{enumerate}[(1)]
		\item \label{it:conf-overlap} If $uv \to x$ and $vw \to y$ are rules of $R$ then there is a $z \in A^*$ such that $xw \to^*_R z$ and $uy \to^*_R z$.
		\item \label{it:conf-middle} If $uvw \to x$ and $v \to y$ are rules of $R$ then there is a $z \in A^*$ such that $x \to^*_R z$ and $uyw \to^*_R z$.
	\end{enumerate}
\end{theorem}

In fact, a rewriting system is confluent, not just locally confluent, if it satisfies the above condition. However, local confluence is sufficient for our purposes because the rewriting system we will consider in \cref{sec:special-monoids} is noetherian so we can apply \cref{thm:newman}.

\begin{proof}[ \pCref{thm:confluent-cond}]
	The `only if' direction is straightforward. To show the `if' direction, suppose $a, x, y$ are strings such that $a \to_R x$ through a rule $u \to v$ and $a \to_R y$ through a rule $u' \to v'$. Then $a$ contains $u$ as a substring, i.e. $a = AuZ$ for some $A, Z \in A^*$. The string $u'$ must also occur somewhere in $a$. There are five possibilities for its location, and in each case we show that a common descendant $z \in A^*$ exists for $x$ and $y$ and hence that $R$ is locally confluent.

	\textbf{Case (i)}: $u'$ is entirely contained in $A$. Write $a = Bu'CuZ$, so that $A = Bu'C$. Then \[
		\begin{array}{lllll}
			& & Au'CvZ & & \\
			& \nearrow & & \searrow & \\
			a = Bu'CuZ & & & & Av'CvZ, \\
			& \searrow & & \nearrow & \\
			& & Av'CuZ & &
		\end{array}
	\]
	so $z = Av'CvZ$ works.

	\textbf{Case (ii)}: $u'$ is contained in $Au$ but not in $A$ or $u$. Factor $a = BCDEZ$ as follows, so that $u = DE$ and $u' = CD$:

	{\centering
	\begin{tikzpicture}
		\filldraw[fill=gray!20] (0,0) rectangle (2,0.5) node[midway] {$A$};
		\draw[<->] (0.05,0.6) -- (0.75,0.6) node[above,midway] {$B$};
		\draw[dashed] (0.8,0) -- (0.8,0.5);
		\draw[<->] (0.85,0.6) -- (1.95,0.6) node[above,midway] {$C$};
		\draw[solid] (2,0) -- (2,0.5);
		\filldraw[fill=gray!20] (2,0) rectangle (4,0.5) node[midway] {$u$};
		\draw[<->] (2.05,0.6) -- (2.75,0.6) node[above,midway] {$D$};
		\draw[<->] (0.85,-0.1) -- (2.75,-0.1) node [below,midway] {$u'$};
		\draw[dashed] (2.8,0) -- (2.8,0.5);
		\draw[<->] (2.85,0.6) -- (3.95,0.6) node[above,midway] {$E$};
		\filldraw[fill=gray!20] (4,0) rectangle (6,0.5) node[midway] {$Z$};
	\end{tikzpicture}\par}

	Then we have rules $CD \to v'$ and $DE \to v$ in $R$, so by hypothesis there is a $z \in A^*$ such that $v'E \to^*_R z$ and $Cv \to^*_R z$, and we have a common descendant like so: \[
		\begin{array}{lllll}
			& & Bv'EZ & & \\
			& \nearrow & & \searrowstar & \\
			a = BCDEZ & & & & BzZ. \\
			& \searrow & & \nearrowstar & \\
			& & BCvZ & &
		\end{array}
	\]

	\textbf{Case (iii)}: $u'$ is entirely contained in $u$. Factor $a = ABu'CZ$ so that $u = Bu'C$. Then by hypothesis there is a $z \in A^*$ such that $v \to^* z$ and $Bv'C \to^* z$. So we have the diagram: \[
		\begin{array}{lllll}
			& & ABv'CZ & & \\
			& \nearrow & & \searrowstar & \\
			a = ABu'CZ & & & & AzZ. \\
			& \searrow & & \nearrowstar & \\
			& & AvZ & &
		\end{array}
	\]

	\textbf{Case (iv)}: $u'$ is contained in $uZ$ but not in $u$ or $Z$. Factor $a = ABCDE$ as below, so that $u = BC$, $u' = CD$ and $Z = DE$:

	{\centering
	\begin{tikzpicture}
		\filldraw[fill=gray!20] (0,0) rectangle (2,0.5) node[midway] {$A$};
		\draw[<->] (2.05,0.6) -- (2.75,0.6) node[above,midway] {$B$};
		\draw[<->] (2.85,0.6) -- (3.95,0.6) node[above,midway] {$C$};
		\draw[solid] (2,0) -- (2,0.5);
		\filldraw[fill=gray!20] (2,0) rectangle (4,0.5) node[midway] {$u$};
		\draw[<->] (4.05,0.6) -- (4.75,0.6) node[above,midway] {$D$};
		\draw[dashed] (2.8,0) -- (2.8,0.5);
		\draw[<->] (4.85,0.6) -- (5.95,0.6) node[above,midway] {$E$};
		\filldraw[fill=gray!20] (4,0) rectangle (6,0.5) node[midway] {$Z$};
		\draw[dashed] (4.8,0) -- (4.8,0.5);
		\draw[<->] (2.85,-0.1) -- (4.75,-0.1) node [below,midway] {$u'$};
	\end{tikzpicture}\par}

	Since we have rules $BC \to v$, $CD \to v'$, by hypothesis there is a $z \in A^*$ such that $vD \to^* z$ and $Bv' \to z$, giving the diagram: \[
		\begin{array}{lllll}
			& & AvDE & & \\
			& \nearrow & & \searrowstar & \\
			a = ABCDE & & & & AzZ. \\
			& \searrow & & \nearrowstar & \\
			& & ABv'E & &
		\end{array}
	\]

	\textbf{Case (v)}: $u'$ is entirely contained in $Z$. This case is very similar to case (i) and is omitted.
\end{proof}

A slightly different characterisation of confluence, which is often more useful when considering a particular, concrete rewriting system, comes from the notion of \dn{critical pairs}.

\begin{defn}
	Let $R$ be a rewriting system over an alphabet $A$, and let $u, v \in A^*$, $u \ne v$. Then $(u, v)$ is a \dn{critical pair} of $R$ if there is a string $w \in A^*$ such that $w \to_R u$ and $w \to_R v$.
\end{defn}

That is, a critical pair is a pair of distinct words which arise as the result of rewriting the same string with $R$.

\begin{defn}
	A critical pair $(u, v)$ of a rewriting system $R$ over $A$ is said to \dn{resolve} if there exists $z \in A^*$ such that $u \to^*_R z$ and $v \to^*_R z$.
\end{defn}

It is then straightforward to rephrase \cref{thm:confluent-cond} in the following terms:

\begin{theorem}
	A rewriting system $R$ is locally confluent if every critical pair of $R$ resolves.
\end{theorem}
\begin{proof}
	The conditions (1) and (2) in the statement of \cref{thm:confluent-cond} are exactly the circumstances in which critical pairs can arise. (See \S 2.3 of \cite{Book1993} for more details.)
\end{proof}

\begin{example}
	Consider the rewriting system $R = \{a^3 \to \epsilon, b^2 \to \epsilon, ab \to ba^2\}$. To enumerate the critical pairs of $R$, it suffices to consider when the left hand sides of any two (not necessarily different) rules can overlap.

	\emph{Rule 1}: $a^3 \to \epsilon$. The two possible overlaps are:
	\begin{align*}
		\underline{aaa}a \to \epsilon a = a & \quad & a\underline{aaa} \to a\epsilon = a
	\shortintertext{and}
		\underline{aaa}b \to \epsilon b = b & \quad & aa\underline{ab} \to a\underline{ab}aa \to ab\underline{aaa}a \\
		&&\to \underline{ab}a \to b\underline{aaa} \to b,
	\end{align*}
	which both resolve.

	\emph{Rule 2}: $b^2 \to \epsilon$. The two possible overlaps are:
	\begin{align*}
		\underline{bb}b \to b & \quad & b\underline{bb} \to b
	\shortintertext{and}
		a\underline{bb} \to a & \quad & \underline{ab}b \to b\underline{aaa} \to b,
	\end{align*}
	which also both resolve.

	\emph{Rule 3}: $ab \to ba^2$. We have already considered all the possible overlaps.

	Every critical pair resolves, so $R$ is confluent.
\end{example}

\medskip
\begin{center}*\end{center}

The principal property that confluence guarantees us is the following:

\begin{prop}
	In a confluent rewriting system a string has at most one irreducible descendant. \label{prop:confluent-at-most-one}
\end{prop}
\begin{proof}
	Let $R$ be a confluent rewriting system over an alphabet, and let $u \in A^*$. Suppose $u$ had two irreducible descendants $u'$ and $u''$ in $A^*$. Then since $R$ is confluent, there exists a string $v \in A^*$ such that $u' \to^* v$ and $u'' \to^* v$. But since both these strings are irreducible, the only way for $u' \to^* v$ to be true is if $u' = v$, and hence $u' = v = u''$. Therefore if $u$ has an irreducible descendant, it must be unique.
\end{proof}

\subsection{Normal forms} \label{sec:normal-forms}

The idea of a normal form comes from the following result:

\begin{prop}
	With respect to a confluent noetherian rewriting system, every string $u \in A^*$ has exactly one irreducible descendant.
\end{prop}
\begin{proof}
	Let $R$ be a confluent noetherian rewriting system over an alphabet $A$, and let $u \in A^*$. Then since $R$ is noetherian, by \cref{prop:noetherian-every-irred} the word $u$ has an irreducible descendant $u' \in A^*$. Finally, by \cref{prop:confluent-at-most-one}, this irreducible descendant $u'$ must be unique.
\end{proof}

We refer to this irreducible descendant $u'$ as the \dn{normal form} for $u$, which will for a general word $u$ be denoted $\bar u$. We can in fact say more than this:

\begin{theorem}
	Let $R$ be a confluent noetherian rewriting system and $u \in A^*$. Then if $u =_R v$, then $\bar u =_R \bar v$.
\end{theorem}
\begin{proof}
	Let $R$ be such a rewriting system, and let $u, v \in A^*$ such that $u =_R v$. Since $u \to_R^* \bar u$, $u =_R \bar u$; and since $v \to_R^* \bar v$, $v =_R \bar v$ and so by transitivity of $=_R$, $\bar u =_R \bar v$.
\end{proof}

Recall from \cref{sec:rws-presentations} that if we have a presentation $\Mon \langle A \mid R \rangle$, the monoid it presents is given by the quotient $A^*/{=_R}$. Thus the theorem above gives each equivalence class, i.e. every element in the monoid, a unique representative. If we had a way of computing this normal form for an element given by any word, we could compare two elements --- i.e. solve the word problem --- by computing their normal forms and comparing those letter by letter.

Since we are considering confluent noetherian rewriting systems, the following simple algorithm accomplishes this very task:

\begin{algorithm} The rewriting algorithm: \label{alg:rewrite}

\hspace{0.05\textwidth}
\parbox[t]{0.9\textwidth}{
	\textbf{Input:} a confluent noetherian rewriting system $R$ over an alphabet $A$; a word $w \in A^*$ \\
	\textbf{Output:} the normal form $\bar w$ of $w$
	\medskip

	\begin{enumerate}
		\item Let $w' \leftarrow w$.
		\item For every rule $u \to v$ in $R$:	\label{nfal-for-every-rule}
			\begin{enumerate}
				\item Scan the string $w'$ from left to right to try to find an occurence of $u$.
				\item If one is found, then we can write $w' = AuB$. Set $w' \leftarrow AvB$ and return to step \ref{nfal-for-every-rule}. It should be clear that $AuB =_R AvB$.
			\end{enumerate}
		\item If we reach this point, then $w'$ is irreducible and so we can set $\bar w \leftarrow w'$.
	\end{enumerate}
}
\end{algorithm}

The crucial question we ask about this algorithm is then: does it halt on any input? Since $R$ is assumed to be noetherian, the string can only be reduced finitely many times before we encounter an irreducible element. So the algorithm halts on any input as long as the number of rules in $R$ is finite (otherwise the loop in step \ref{nfal-for-every-rule} would never terminate). In fact, it is sufficient that there are only a finite number of rules which can apply to any particular $w'$, and that this set of rules can be enumerated in finite time. For example, if the set of rules was stored in order of the length of the left hand side, and there are only finitely many rules of any given length, then we can simply check all rules until the length of one exceeds the length of $w'$.

This is essentially the argument we will use in \cref{sec:special-monoids} to conclude that the word problem is decidable.

\section{The word problem for one-relation special monoids} \label{sec:special-monoids}

In this section, we discuss the word problem for a special class of one-relation semigroups, namely `special' one-relation monoids.

\begin{defn} \label{def:special}
	A monoid $M$ is \dn{special} if it has a presentation of the form $\langle A \mid w_1 = \epsilon, w_2 = \epsilon, \ldots, w_n = \epsilon \rangle$ for nonempty words $w_i \in A^*$.
\end{defn}

The main result is a theorem of Adjan, which states that the word problem is indeed decidable for one-relation special monoids:

\begin{theorem}[Adjan] \label{thm:ors-decidablewp}
	Let $M$ be a one-relation special monoid, i.e. a monoid admitting a presentation of the form $\langle A \mid w = \epsilon\rangle$, where $A$ is an alphabet, $w \in A^+$. Then $M$ has decidable word problem.
\end{theorem}

Here, we follow Zhang's proof from \cite{Zhang1992a}, which uses rewriting systems to obtain a dramatic simplification of Adian's first proof in \cite{Adian1966}. Zhang's overall approach is to construct a one-relation presentation for the group of units of the special monoid --- whose word problem is then decidable by Magnus' theorem --- and reduce the word problem of the whole monoid to that of the group of units using a confluent, noetherian rewriting system.

In another paper \cite{Zhang1992}, Zhang uses a similar method to generalise this statement by reducing the word problem of any special monoid to the word problem of its group of units, as well as obtaining similar results on the conjugacy and divisibility problems for these monoids.


\subsection{Constructing a generating set} \label{sec:constructing-genset}

Suppose $M = \langle A \mid w = \epsilon\rangle$ is a finitely presented monoid.

Given a subset $X \subseteq A^*$ of words, define
	\begin{align*}
		L(X) &= \{ x \in A^+ \mid \exists\ w \in A^* \colon wx \in X \} \text{ and } \\
		R(X) &= \{ x \in A^+ \mid \exists\ w \in A^* \colon xw \in X \}
	\end{align*}
to be the set of left and right factors respectively of words in $X$, and let $W(X) = L(X) \cap R(X)$ be the set of words which are both left and right factors each of some word in $X$.

Taking $C_1 = \{w\}$, let
	\[ C_{i+1} = C_i \cup \{ xy \mid y \in W(C_i), yx \in C_i \} \cup \{ yz \mid y \in W(C_i), zy \in C_i \} \]
be those words obtained by moving right factors from $W(C_i)$ to the beginning of the words in $C_i$ in which they appear and left factors to the end of words.

To see why we do this, consider as an example the monoid $N = \langle a, b, c \mid bcab = \epsilon \rangle$. Clearly, the word $bcab$ is invertible in $N$, since it is the identity. Notice also that $L(\{bcab\}) \cap R(\{bcab\}) = \{b, bcab\}$. The letter $b$ appears at the start and end of the word: $bca \cdot b = \epsilon$ and $b \cdot cab = \epsilon$. That is, $bca$ is a left inverse for $b$ and $cab$ is a right inverse for $b$.

Since left and right inverses are the same, it must also follow that $b \cdot bca = \epsilon$ and $cab \cdot b = \epsilon$. These resulting words are also invertible in $N$, so we can repeat the process to gather together all the trivial words which arise in this way. We will discuss this more carefully in the proof of \cref{prop:M'-is-group}.


\begin{lemma}
	For each index $i$, every word in $C_i$ has the same length as $w$. \label{lma:Ci-length-w}
\end{lemma}
\begin{proof}
	This can be shown by a straightforward induction on $i$. It is true in $C_1$, since $C_1 = \{w\}$. So suppose every word in $C_i$ has length $|w|$, and let $xy$ be a new word in $C_{i+1}$ for some $x, y \in A^+$ such that $x$ or $y$ is in $W(C_i)$. Then either $xy$ or $yx$ is in $C_i$ and hence $|xy| = |yx| = |w|$ by the inductive hypothesis. Hence every word in $C_{i+1}$ has length $|w|$ and so every word in $C_i$ has length $|w|$, for any index $i$.
\end{proof}

It follows from the above that since $|C_i| \le |A|^{|w|}$ (which is finite since $M$ is finitely presented) and $C_{i+1} \supseteq C_i$ for all $i \ge 1$, there is a maximal set $C_k$. Define a new set $E(M)$ to be those words in $W(C_k)$ which have no proper right factors in $W(C_k)$.

This set $E(M)$ will effectively serve as the generating set in the presentation for the group of units of $M$ which we construct in the remainder of the proof.

\begin{example} \label{ex:Ck-group}
	Consider the monoid $M$ defined by the presentation $\langle b, c \mid bcb = \epsilon \rangle$. Running the procedure again we obtain:

	\begin{center}
	\renewcommand{\arraystretch}{1.2}
	\begin{tabular}{r|ll}
		$i$ & $C_i$ & $W(C_i)$ \\ \hline
		1 & $\{bcb\}$ & $\{b, bcb\}$ \\
		2 & $\{cbb, bbc, bcb\}$ & $\{cbb, c, b, bb, bc, cb, bbc, bcb\}$
	\end{tabular}
	\end{center}

	Notice that both generators $b$ and $c$ are in $W(C_2)$, so $C_2$ contains every cyclic permutation of $bcb$. Hence $C_k = C_2$ and so $E(M) = \{ b, c\}$. Since $E(M)$ is supposed to generate the group of units of $M$, this suggests (correctly) that every generator, and hence every element, of the monoid is invertible, i.e. that $M$ is in fact a group. 
\end{example}

\begin{example}
	Consider the bicyclic monoid, given by the presentation $B = \langle b, c \mid bc = \epsilon \rangle$.
	Applying the above construction, we find:

	\begin{center}
	\renewcommand{\arraystretch}{1.2}
	\begin{tabular}{r|ll}
		$i$ & $C_i$ & $W(C_i)$ \\ \hline
		1 & $\{bc\}$ & $\{bc\}$ \\
		2 & $\{bc\}$ & $\{bc\}$
	\end{tabular}
	\end{center}

	So $C_k = C_1 = \{ bc \}$, and hence $E(B) = \{bc\}$. This suggests that the only invertible element in $B$ is the identity $(bc)^n = bc = \epsilon$.
\end{example}

\begin{example} \label{ex:monoidN}
	For a less extreme example, look at the monoid $N$ from earlier with defining presentation $\langle a, b, c \mid bcab = \epsilon\rangle$. Performing the computations:

	\begin{center}
	\renewcommand{\arraystretch}{1.2}
	\begin{tabular}{r|ll}
		$i$ & $C_i$ & $W(C_i)$ \\ \hline
		1 & $\{bcab\}$ & $\{b, bcab\}$ \\
		2 & $\{bbca, cabb, bcab\}$ & $\{b, bb, bbca, ca, bcab, bca, cabb, cab\}$
	\end{tabular}
	\end{center}

	This gives $C_k = C_2 = \{bbca, cabb, bcab\}$ and hence $E(N) = \{b, ca\}$. Notice that in this case, as in our previous examples, the relator $bcab$ can be expressed as a product of the words in $E(N)$.

\end{example}

The tables above and the sets $E(M)$ for the above presentations were computed using a simple GAP program; see \cref{sec:E(M)-program} for a listing.


\subsection{Defining the presentation} \label{sec:defining-presentation}

Define a new alphabet $B$ disjoint with $A$ such that we have a bijection $\midtilde\phi \colon E(M) \to B$, and let $\phi \colon E(M)^* \to B^*$ be the unique homomorphic extension of $\midtilde\phi$ to $E(M)^*$. By the following result, $\phi(w)$ is well-defined:

\begin{prop} \label{lma:relator-factors-E(M)}
	The relator $w$ is a product of factors in $E(M)$.
\end{prop}
\begin{proof}
	\hspace{-0.25mm}We show by induction on word length that every element of $W(C_k)$ is a product of factors in $E(M)$. First suppose that $u \in W(C_k)$ is of minimal length in $W(C_k)$. Then $u$ has no proper factors in $W(C_k)$, and so $u \in E(M)$.

	Now suppose that all strings in $W(C_k)$ with length less than $n$ are products of factors in $E(M)$, and let $u \in W(C_k)$ have length $n$. If $u$ has no proper right factors in $W(C_k)$, then it is in $E(M)$ by definition. Otherwise, we can write $u = ve$ for $e \in E(M)$, $v \in A^+$.

	We want to show that $v \in W(C_k)$, so that by the inductive hypothesis (since $|v| < n$), $v \in E(M)^*$ and hence $u \in E(M)^*$. Since $v$ is a prefix of $u$, for $v$ to be in $W(C_k)$ it remains only to show that it is a suffix of some word in $C_k$. Because $u \in W(C_k)$, there is some word $x \in C_k$ such that $x = x'u = x've$ . Then by the definition of $C_{k+1}$, since $e \in W(C_k)$, the word $ex'v \in C_{k+1}$. But $C_{k+1} = C_k$, so $v$ is indeed a suffix of a word in $C_k$.

	Altogether, this means $u$ is a product of factors in $E(M)$ and so by induction all the words of $W(C_k)$ are such a product. In particular, since $w \in W(C_k)$, $w$ is a product of factors in $E(M)$.
\end{proof}

Having introduced this map $\phi$, it is best to consider some of its properties now, as we shall use it throughout. In particular, $\phi$ is an isomorphism.

\begin{lemma}
	The map $\phi$ is an isomorphism. \label{lma:phi-isomorphism}
\end{lemma}
\begin{proof}
	The function is a homomorphism by construction, therefore we need only show it is a bijection. First, we show $\phi$ is injective. Suppose $e = e_1\cdots e_m$ and $f = f_1\cdots f_n$ are in $E(M)^*$. Then
	\begin{alignat*}{2}
		&& \phi(e) &= \phi(f) \\
		\implies\quad&& \phi(e_1 \cdots e_m) &= \phi(f_1 \cdots f_n) \\
		\implies\quad&& \tilde\phi(e_1)\cdots\tilde\phi(e_m) &= \tilde\phi(f_1)\cdots\tilde\phi(f_n).
	\end{alignat*}
	Each term on both sides is simply one element of $B$, so for them to be equal, we must have $m = n$ and $\tilde\phi(e_i) = \tilde\phi(f_i)$ for each $1 \le i \le n$. Since $\tilde\phi$ is a bijection, we therefore have $e_i = f_i$ for each $i$ and hence $e = f$.

	Finally, $\phi$ is surjective since if $b = b_1 \cdots b_n \in B^*$, then $\phi(\tilde\phi^{-1}(b_1) \cdots \tilde\phi^{-1}(b_n)) = \tilde\phi(\tilde\phi^{-1}(b_1)) \cdots$ $\tilde\phi(\tilde\phi^{-1}(b_n)) = b_1$$\cdots b_n = b$. Therefore $\phi$ is an isomorphism.
\end{proof}

We now define a monoid $M'$ given by the presentation $\langle B \mid \phi(w) = \epsilon \rangle$. We assert that this monoid is in fact a group:

\begin{prop} \label{prop:M'-is-group}
	The monoid $M' = \langle B \mid \phi(w) = \epsilon\rangle$ is a group.
\end{prop}
\begin{proof}
	It suffices to show that every generator of $M'$ is invertible. We first show by induction that for all $i$, every word in $C_i$ is trivial in $M$. In the base case $C_1$, the only word to consider is $w$ itself, which is trivial by the defining relation $w = \epsilon$. Suppose then that all words in $C_j$ are trivial, for each $j \le i$, and consider a word $v \in C_{i+1}$, $v \not\in C_i$.

	This new word $v$ can arise in two ways. In the first case, $v = xy$ for some $y \in W(C_i)$, $yx \in C_i$. So by the inductive hypothesis, $yx =_M \epsilon$, i.e. $x$ is a right inverse for $y$ in $M$. As $y \in W(C_i)$, there is a word $u \in C_i$ such that $u = u'y =_M \epsilon$ for some $u' \in A^*$. So $u'$ is a left inverse for $y$ in $M$. We have a left and a right inverse for $y$ in $M$, so they must be equivalent in $M$, hence $v = xy =_M u'y =_M u$. But $u$ is in $C_i$ and so is trivial by the inductive hypothesis. Therefore $v =_M \epsilon$ as required.

	A similar argument shows that $v$ is trivial in $M$ if $v = yz$ for $y \in W(C_i)$, $zy \in C_i$. This accounts for every word in $C_{i+1}$, and so by induction all words in $C_j$ are trivial in $M$, for every index $j$. In particular, all the words in $C_k$ are trivial.

	For any word $z \in W(C_k)$, there are words $a, b$ in $C_k$ such that $a = za'$ and $b = b'z$ for some $a', b' \in A^*$. Since these words $a$ and $b$ are trivial in $M$, $a'$ is a right inverse for $z$ and $b'$ is a left inverse for $z$ in $M$ and hence $z$ is invertible in $M$. In particular, it follows that every word in $E(M)$ is invertible.

	To conclude, let $b \in B$ be a generator of $M'$. Then $\tilde\phi^{-1}(b) \in E(M)$ has an inverse $\midbar b$ in $M$. Hence $\epsilon =_M \tilde\phi^{-1}(b) \midbar{b}$ and so $\epsilon =_{M'} b\phi(\midbar{b})$; and likewise $\phi(\midbar{b})b = \epsilon$. The arbitrary generator $b$ of $M'$ is hence invertible, so $M'$ is a group.
\end{proof}

The final property of $\phi$ we need is that it behaves well with respect to our monoids $M$ and $M'$.

\begin{prop}
	Let $u, v \in E(M)^*$. Then $u =_M v$ if and only if $\phi(u) =_{M'} \phi(v)$. \label{prop:phi-compatible-MM'}
\end{prop}
\begin{proof}
	Suppose $u =_M v$. Since $u =_M v$ if and only if $u \leftrightst_M v$, whenever $u =_M v$ there must be a sequence of derivations $u = u^{(0)} \leftrightarrow_M u^{(1)} \leftrightarrow_M \cdots \leftrightarrow_M u^{(n-1)} \leftrightarrow_M u^{(n)} = v$. We proceed by induction on the length $n$ of the derivation.

	If $n = 0$, $u = v$ and so $\phi(u) = \phi(v)$.
	
	So suppose the statement holds for derivations of lengths up to $n$, and that $u = u^{(0)} \leftrightarrow_M \cdots \leftrightarrow_M u^{(n)} \leftrightarrow_M u^{(n+1)} = v$. Write $U = u^{(n)}$. Then $\phi(u) =_{M'} \phi(U)$ by the inductive hypothesis, and so we need to show that $\phi(U) =_{M'} \phi(v)$. Since $U \leftrightarrow_M v$, we have two cases.

	If $U \to_M v$, then since $w \to \epsilon$ is the only rule in $M$, we can choose $U'$ and $U'' \in A^*$ such that $U = U'wU''$ and $U'U'' = v$. Then since $\phi$ is a homomorphism, $\phi(U) = \phi(U')\phi(w)\phi(U'') $. By definition, $\phi(w) =_M \epsilon$, so $\phi(U) =_{M'} \phi(U')\phi(U'') = \phi(U'U'') = \phi(v)$.

	On the other hand, if $U \leftarrow_M v$, then $v \to_M U$ and a symmetrical argument to the previous case shows that $\phi(v) =_{M'} \phi(U)$. Therefore by induction $\phi(u) =_{M'} \phi(v)$ for all $u, v$ such that $u \leftrightst_M v$.


	The converse direction follows by a very similar argument, where a word $U$ factors as $U'\phi(w)U''$ and $\phi(w) \to_{M'} \epsilon$ by the definition of $M'$.
\end{proof}

Before continuing, let us apply these results to our monoid $N$ from \cref{ex:monoidN}. We calculated previously that $E(N) = \{b, ca\}$, so write $B = \{\alpha, \beta\}$ with the homomorphism $\phi$ taking $b \mapsto \alpha$ and $ca \mapsto \beta$. The resulting group $N'$ is then given by the monoid presentation $\langle \alpha, \beta \mid \alpha\beta\alpha = \epsilon \rangle$. This is isomorphic to the group we considered in \cref{ex:Ck-group}.

\subsection{The rewriting system}

Let $\prec$ be some linear order on the alphabet $A$, and extend it to a short-lex order $<$ on $A^*$. Then define a rewriting system $R$ on $A^*$ by
	\[ R = \{ (u, v) \mid u, v \in E(M)^*, v < u, \phi(u) =_{M'} \phi(v) \}. \]

We note immediately that $R$ is noetherian: since if $(u, v)$ is a rule in $R$, then we must have $v < u$, and the short-lex order $<$ is a well-founded relation by a result from the previous section.

This system $R$ is equivalent to the system $\{(w, \epsilon)\}$, i.e. they present the same monoid:
\begin{lemma} \label{lma:R-equivalent-to-pres}
	The rewriting systems $\{(w, \epsilon)\}$ and $R$ are equivalent in the sense that their induced congruences  are equal, and hence $\langle A \mid w \rangle$ = $\langle A \mid \{u = v : (u, v) \in R\}\rangle$.
\end{lemma}
\begin{proof}
	First, observe that $w \in E(M)^*$ by \cref{lma:relator-factors-E(M)}; $\epsilon < w$; and $\phi(w) =_G \epsilon$ follows immediately from the presentation for $G$, so $(w, \epsilon)$ is a rule in $R$ and hence $\leftrightst_{\{(w,\epsilon)\}}\ \subseteq\ \leftrightst_R$.

Conversely, suppose $(u, v)$ is a rule in $R$. Then $\phi(u) =_G \phi(v)$ means $\phi(u) \leftrightst_{\{(\phi(w), \epsilon)\}} \phi(v)$, and since $\phi$ is a homomorphism, $u \leftrightst_{\{(w, \epsilon)\}} v$. So $\leftrightst_R\ \subseteq\ \leftrightst_{\{(w,\epsilon)\}}$.

Hence the two rewriting systems are equivalent.
\end{proof}


\subsubsection{\texorpdfstring{Some lemmas on $E(M)$}{Some lemmas on E(M)}}

We state here two lemmas about the generating set $E(M)$ which will be useful to prove that $R$ is confluent:

\begin{lemma} \label{lma:no-middle-E(M)}
	If $x, y, z \in A^*$ are strings such that $xy, yz \in E(M)$, then either $y = \epsilon$ or $x = z = \epsilon$.
\end{lemma}
\begin{proof}
	Suppose $y \ne \epsilon$. Then since $xy \in E(M)$, $xy \in W(C_k)$ and in particular, $xy \in L(C_k)$, so there is some $\alpha \in A^*$ such that $\alpha x \cdot y \in C_k$. So $y$ is a right factor of a word in $C_k$, i.e. $y \in R(C_k)$. Likewise, $yz \in R(C_k)$ so $y \cdot z\beta \in C_k$ for some $\beta \in A^*$ and $y \in L(C_k)$. Hence $y \in W(C_k)$. By the definition of $E(M)$, $xy$ has no proper right factor in $W(C_k)$, so $y$ must not be a proper factor; but by assumption, $y \ne \epsilon$, so we must have $x = \epsilon$. Similarly, $yz$ has no proper right factor in $W(C_k)$, so $z$ is not a proper factor and $z = \epsilon$.
\end{proof}

\begin{cly} \label{cly:middle-E(M)*}
	If $x, y, z \in A^*$ are strings such that $xy, yz \in E(M)^*$, then $y \in E(M)^*$. \incomplete
\end{cly}


\subsubsection{\texorpdfstring{Confluence of $R$}{Confluence of R}}

We apply \cref{thm:confluent-cond} directly to $R$ to show that it is locally confluent. Since $R$ is noetherian, by \cref{thm:newman} this suffices to show $R$ is confluent. Recall that \cref{thm:confluent-cond} states:

\begin{theorem*}
	A rewriting system $R$ over an alphabet $A$ is locally confluent if and only if the following hold for all strings $u, v, w, x, y \in A^*$:
	\begin{enumerate}[(1)]
		\item If $uv \to x$ and $vw \to y$ are rules of $R$ then there is a $z \in A^*$ such that $xw \to^*_R z$ and $uy \to^*_R z$.
		\item If $uvw \to x$ and $v \to y$ are rules of $R$ then there is a $z \in A^*$ such that $x \to^*_R z$ and $uyw \to^*_R z$.
	\end{enumerate}
\end{theorem*}


For part \ref{it:conf-overlap}, suppose $uv \to_R x$ and $vw \to_R y$, with $uv \ne vw$ (if they are equal, we have nothing to prove). We claim that in fact one of $xw \to uy$ or $uy \to xw$ is a rule in $R$ and so $uy$ or $xw$ is a suitable $z$. By the definition of $R$, $uv, vw, x, y\in E(M)^*$, and so by \cref{cly:middle-E(M)*}, $v \in E(M)^*$. Hence $u, w \in E(M)^*$ and $uy, xw \in E(M)^*$. Now observe that by the rules we know are in $R$ and the fact $\phi$ is a homomorphism, we have $\phi(xw) = \phi(x)\phi(w) =_G \phi(uv)\phi(w) = \phi(u)\phi(vw) =_G \phi(u)\phi(y) = \phi(uy)$. Finally, since $<$ is linear, either $xw < uy$, in which case $uy \to xw$ is a rule in $R$; or $uy < xw$, in which case $xw \to uy$ is a rule in $R$ as required.

Now consider condition \ref{it:conf-middle}: suppose $uvw \to_R x$ and $v \to_R y$, and again assume that $v \ne y$. Observe that $\phi(x) =_G \phi(uyw)$, since $\phi(uvw) =_G \phi(x)$ and $\phi(v) =_G \phi(y)$. Furthermore, either $uyw < x$ or $x < uyw$. So as before, if $uyw \in E(M)^*$, then one of $x$ or $uyw$ will be a suitable $z$. Since $uvw, v, y \in E(M)^*$, if $uyw \not\in E(M)^*$, then $u = u_1u_2 \cdots u_m U$ and $w = W w_1 w_2 \cdots w_n$ for $u_i, w_i \in E(M)$ and some non-empty strings $U$ and $W$, with $UvW \in E(M)$. This means $v$ must be shorter than the longest word in $E(M)$ (or $UvW$ would be longer and therefore not in $E(M)$).

The following lemma completes the proof:

\begin{lemma} \label{lma:shorter-irreducible}
	Any word $a \in A^*$ shorter than the longest word in $E(M)$ is irreducible by $R$.
\end{lemma}
\begin{proof}
	Let $L$ be a word of maximal length in $E(M)$, and suppose $a$ were reducible. Then we can write $a = a'ba''$ where $b \in E(M)^*$ and $b \to_R c$ for some $c \in E(M)^*$. Then $c < b$ and so $|c| \le |b| \le |a| < |L|$, and hence $L$ cannot appear in $b$ or $c$.
	
	We then recall the Freiheitssatz for one-relator groups (\cref{thm:freiheitssatz}).	Since $b \to_R c$, $\phi(b) =_G \phi(c)$. Then as $L$ is not in $b$ or $c$, $\phi(L)$ is not in $\phi(b)$ or $\phi(c)$, i.e. $\phi(b)$ and $\phi(c)$ are in the subgroup of $G$ generated by $B \setminus \{\phi(L)\}$. This is free by the Freiheitssatz, and so $\phi(b) = \phi(c)$ as words. By \cref{lma:phi-isomorphism}, $\phi$ is an isomorphism; in particular, it is injective and so $b = c$. But $c < b$, so we have a contradiction and $a$ is indeed irreducible.
\end{proof}

It follows from this that $v$ is irreducible by $R$; but this is impossible, since by hypothesis $v \to_R y$. So in fact $uyw \in E(M)^*$, and one of $uyw \to_R x$ or $x \to_R uyw$ holds. Therefore condition \ref{it:conf-middle} is satisfied and $R$ is confluent.


\subsection{The word problem is decidable}

We can now prove \cref{thm:ors-decidablewp}. We essentially use the argument in \cref{sec:normal-forms} using our confluent, noetherian rewriting system $R$. For the rewriting algorithm (\cref{alg:rewrite}) to halt, we required that only a finite number of rules applied to any given word $u \in A^*$, and that there was a procedure which could enumerate this set in a finite number of steps.

Start by simply enumerating all pairs $(a, b)$ of strings of length $|u|$ or less. It is decidable to compare $a$ and $b$ under the short-lex order, i.e. to determine if $b < a$. Furthermore, by Magnus' theorem (\cref{thm:orgp-decidablewp}), it is decidable whether $a =_G b$. If and only if both of these hold is $a \to b$ a rule in $R$. There are a finite number of these pairs $(a, b)$, so we have our required procedure.

Given two words $u, v \in A^*$, we can thus obtain their normal forms $\bar u$ and $\bar v$ with respect to $R$ in a finite number of steps and, comparing these letter by letter, determine if $u =_R v$. Therefore it is decidable whether $u =_R v$.

The rewriting system $R$ is equivalent to $\{(w, \epsilon)\}$ by \cref{lma:R-equivalent-to-pres}, and since $\{(w, \epsilon)\}$ presents our monoid $M$, $u =_R v$ if and only $u =_M v$. This is precisely the word problem for $M$, and so we have shown that the word problem for a one-relator special monoid is decidable.


\section{The structure of one-relation special monoids} \label{sec:structure}

The rewriting system discussed in the previous section can be used to solve more than just the word problem for special monoids. In this section, we will discuss how it can be used to describe significant parts of the structure of the monoid $M$ --- in particular, we will finally prove that the group $G$ from \cref{sec:defining-presentation} is the group of units. With this established, we shall explore the submonoids of right and left units of $M$, and show how they admit a simple (and surprising) characterisation as a free product of $G$ and a free semigroup.

\subsection{An alternative approach}

In \cite{Zhang1992}, an alternative, non-constructive definition of a generating set for the group of units is given, based on the idea of \emph{minimal factors} of $w$.

\begin{defn}
	A word $v \in A^+$ is \dn{minimal} if:
	\begin{enumerate}[(i)]
		\item it is invertible in $M$,
		\item $|v| \le |w|$ and
		\item none of its nonempty prefixes are invertible in $M$.
	\end{enumerate}
\end{defn}

We can then write the relator $w$ in terms of minimal factors $w = w_1w_2\ldots w_n$. Let $\Delta$ be the set of all minimal words which are congruent to some minimal factor of $w$, that is
	\[ \Delta = \{ u \in A^* \mid u =_M w_i \text{ for some } i, u\text{ minimal} \}. \]

\begin{lemma}
	In a one-relation special monoid, $\Delta = \{w_1, \ldots, w_n\}$. \incomplete
\end{lemma}
\begin{proof}
	If $w$ is the only minimal factor of $w$, then since any minimal word must be no longer than $w$, $w$ is the only word in $\Delta$.

	Otherwise, let $1 \le i \le n$ and consider the set $\Delta_i = \{ u \in A^* \mid u =_M w_i \}$. Since all the words in this set are congruent in $M$, and the congruence of $R$ is equal to the congruence of $M$, it follows from the fact that $R$ is confluent and noetherian that there is a unique element $\bar u \in \Delta_i$ which is irreducible by $R$.
%Then there are $A, B, x, y \in A^*$ such that $w_i = AxB$, $w_i' = AyB$ and $x \to y$ is a rule in $R$. By the definition of $R$, $|x| \ge |y|$ and $x, y \in E(M)^*$.
\end{proof}

As might be expected, $E(M)$ plays a parallel role to $\Delta$ in this approach:

\begin{prop}
	The sets $E(M)$ and $\Delta$ are equal; that is, $E(M)$ is the set of minimal factors of $w$. \incomplete
\end{prop}
\begin{proof}
	We first show that every word in $E(M)$ is minimal, and so $E(M) \subseteq \Delta$. By the proof of \cref{prop:M'-is-group}, every element of $E(M)$ is invertible in $M$. Furthermore, since every word in $E(M)$ is a factor of a word in $W(C_k)$, and every word in $C_k$ has length $|w|$ by \cref{lma:Ci-length-w}, no word in $E(M)$ can be longer than $|w|$. So it remains to show that for any $u \in E(M)$, no nonempty prefixes of $u$ are invertible.

	Suppose, for a contradiction, that $u$ factors as $u = u'u''$ such that $u', u'' \in A^+$ and $u'$ is invertible.

	We now show the converse. Factor $w$ over $E(M)$ as $w = \alpha_1 \alpha_2 \cdots \alpha_m$ and over $\Delta$ as $\beta_1 \beta_2 \cdots \beta_n$.

	\emph{Case 1.} Suppose $|\alpha_m| < |\beta_n|$. Then $\beta_n = X\alpha_m$ for some $X \in A^+$. Since $\beta_n$ is invertible, it has an inverse $\overline{\beta_n}$ such that $\overline{\beta_n}X\alpha_m =_M \epsilon$ and hence $X =_M \beta_n\overline{\alpha_m}$. This contradicts $\beta_n$ being minimal, since $X$ is now a nonempty invertible prefix.

	\emph{Case 2.} Now suppose $|\alpha_m| > |\beta_n|$. Then $\alpha_m = Y\beta_n$ for some $Y \in A^+$, and so $\beta_{n-1} = VY$ for some $V \in A^*$. Since $\beta_n$ is invertible, $Y =_M \alpha_m\overline{\beta_m}$, and hence $\beta_{n-1} =_M V\alpha_m\overline{\beta_n}$. As $\alpha_m \in E(M)$, it is invertible, and we conclude that $V =_M \beta_{n-1}\beta{n}\overline{\alpha_m}$. This is a product of invertible elements and so $V$ is itself invertible. If $V$ is nonempty, then we have a nonempty prefix of $\beta_{n-1}$ which is invertible, contradicting the minimality of $\beta_{n-1}$. Otherwise, $\alpha_m = \beta_{n-1}\beta{n}$ and the invertibilty of $\beta_{n-1}$ contradicts $\alpha_m$ being minimal.

	Hence $|\alpha_m| = |\beta_n|$ and consequently $\alpha_m = \beta_n$. Applying the same argument to the strings $\alpha_1 \cdots \alpha_{m-1}$ and $\beta_1 \cdots \beta_{n-1}$ and so on gives us that $\alpha_i = \beta_i$ for all indices $1 \le i \le m = n$, and therefore that $\Delta \subseteq E(M)$.
\end{proof}


\subsection{The group of units} \label{sec:group-of-units}

Using this framework, we are now in a position to prove that the presentations from \cref{sec:defining-presentation} give the group of units of $M$.

Let $I$ denote the set of nonempty prefixes of words in $E(M)$, that is $I = L(E(M)) \setminus \{\epsilon\}$. Observe that since all words in $E(M)$ are minimal, none of these words are invertible unless they are in $E(M)$. We will need the following factorisation result based around this set:

\begin{lemma}
	Suppose $u \in A^*$ is irreducible by $R$ and right invertible in $M$. Then $u \in I^*$. \label{lma:factor-I*}
\end{lemma}
\begin{proof}
	We proceed by induction on $|u|$. If $|u| = 0$, then $u$ is trivially in $I^*$. Suppose then that $|u| \ge 1$, and that all strings of length strictly less than $|u|$ are in $I^*$.

	Since $u$ is right invertible, it has a right inverse $\bar u \in A^*$ such that $u\bar u =_M \epsilon$ and hence such that $u\bar u \to_R^* \epsilon$. We may assume that $\bar u$ is irreducible by $R$, since reducing $\bar u$ by $R$ does not change either of these facts. Then we can write $u = u'u''$, $\bar u = \bar u'\bar u''$ such that $u\bar u = u'u''\bar u'\bar u'' \to_R u'v\bar u'' \to_R^* \epsilon$, where $u''\bar u' \to v$ is a rule in $R$. By the definition of $R$, this means that $u''\bar u' \in E(M)^*$ and so $u'' \in I^*$. Furthermore, $u'' \ne \epsilon$, since otherwise $\bar u$ would have been reducible by $R$; and hence $|u'| < |u|$.

	Finally, $u' \cdot u''\bar u =_M \epsilon$, i.e. $u'$ is right invertible. So by the inductive hypothesis, $u'$ is a product of the desired form. So is $u''$, hence $u = u'u''$ is also in $I^*$.
\end{proof}

With this in hand, most of the machinery required to complete the proof was introduced in the previous section. Recall that $B$ is an alphabet disjoint from $A$ and in one-to-one correspondence with $E(M)$, and that $\phi : E(M)^* \to B^*$ is the isomorphism induced by this correspondence.

\begin{theorem} \label{thm:Mdash-is-group-of-units}
	The monoid $M' = \langle B \mid \phi(w) = \epsilon \rangle$ is isomorphic to the group of units of $M$.
\end{theorem}
\begin{proof}
	Suppose we have an invertible element of $M$ with irreducible representative $u \in A^*$. In particular, $u$ is right invertible in $M$ and so by \cref{lma:factor-I*}, we can write $u = u_1u_2\cdots u_n$ where $u_i \in I$ for each $1 \le i \le n$. The word $u$ is also left invertible in $M$, so $u^{-1}u_1\cdots u_{n-1}$ is a left inverse for $u_n$.
	% XXX still don't see it
	Hence $u_n$ is invertible. But since $u_n \in I$, we must have that $u_n \in E(M)$. Continuing in this manner, $u_{n-1}$, $u_{n-2}$ and so on are also invertible and hence in $E(M)$. Therefore $u \in E(M)^*$.

	Furthermore, by the proof of \cref{prop:M'-is-group}, every element in $E(M)$ and hence of $E(M)^*$ is invertible in $M$. So $G(M)$ is isomorphic to the submonoid generated by $E(M)^*/{=_M}$.

	% XXX probably need to prove this in more detail in previous section
	Finally, let $\phi$ be the map from \cref{sec:defining-presentation}, and let $\rho_M$ and $\rho_{M'}$ be the congruences associated with the presentations $\{(w, \epsilon)\}$ and $\{(\phi(w), \epsilon)\}$ respectively. Define a map
	\begin{align*}
		\psi : \frac{E(M)^*}{\rho_M} \cong G(M) &\to \frac{B^*}{\rho_{M'}} = M' \\
		u/\rho_M &\mapsto \phi(u)/\rho_{M'}.
	\end{align*}

	This is a surjective homomorphism since $\phi$ is, and is injective and well-defined since $u =_M v$ if and only if $\phi(u) =_{M'} \phi(v)$. Therefore we have an isomorphism from $G(M)$ to $M'$ as required.
\end{proof}


\subsection{Free products}

We will shortly investigate the structure of certain submonoids of our monoid $M$. First, however, we need a way of constructing new semigroups (or other structures) from existing ones which will be useful in our discussion. This \dn{free product} also arises naturally when considering semigroups defined by presentations in general.

\begin{defn}
Let $D = \langle A, R \rangle$ and $E = \langle B, S \rangle$ be semigroups (or monoids, or groups), where $A$ and $B$ are disjoint. Then the \dn{free product} $D \ast E$ of $D$ and $E$ is the semigroup (resp. monoid or group) with the presentation
	\[ D \ast E = \langle A \cup B \mid R \cup S \rangle. \]
\end{defn}

The free product of two semigroups is in a sense the most general semigroup which satisfies all the relations that hold in each of the constituent semigroups.

Elements of a free product take the form of an alternating product
	\[ a_1^{\delta_1} b_1^{\epsilon_1} a_2^{\delta_2} b_2^{\epsilon_2} \cdots a_m^{\delta_m} b_n^{\epsilon_m}, \]
where $a_i \in A$ and $b_i \in B$ for all $i$, $m$ and each $\delta_i$ and $\epsilon_i$ are nonnegative integers (allowing for an empty product when an index is 0). The elements of the first semigroup do not interact with the elements of the second semigroup in any way: there is no relation in $R \cup S$ which involves letters from both $A$ and $B$.

\begin{example}
	If $F_A = \langle A \mid \rangle$ and $F_B = \langle B \mid \rangle$ are free semigroups, then their free product $F_A \ast F_B = \langle A \cup B \mid \rangle$ is again a free semigroup.
\end{example}

\begin{example}
	If $M = \Mon \langle b, c \mid bc = \epsilon \rangle$ and $N = \Mon \langle \beta, \gamma \mid \beta\gamma = \epsilon \rangle$ are two copies of the bicyclic monoid, then $M \ast N = \Mon \langle b, \beta, c, \gamma \mid bc = \epsilon, \beta\gamma = \epsilon \rangle$. Some elements of $M \ast N$ are, in reduced form, $c^3 b$, $\gamma^2\beta^4$, $\beta c b \gamma$, and so on.
\end{example}


\subsection{Left and right units}

Recall that the group of units $G(M)$ of a monoid $M$ is the set of all elements in $M$ which are both left- and right-invertible. It can also be useful to consider the submonoids of `left units' and `right units':

\begin{defn}
	Let $M$ be a monoid. Then the \dn{submonoid of left units} of $M$, denoted $U_l(M)$, is the subset of elements of $M$ which are left-invertible. Analogously, the \dn{submonoid of right units}, denoted $U_r(M)$, is the set of right-invertible elements.
\end{defn}

It should be fairly clear that these sets form a submonoid, but note that they do not necessarily form a group.

In \cite{Zhang1992a}, Zhang uses the presentations from the previous section to give a particularly simple characterisation of the structure of these submonoids in the case where $M$ is special.
\begin{theorem} \label{thm:gen-units-factor-freely}
	Let $M$ be a finitely-presented special monoid. Then $U_r(M) \cong G(M) \ast F$, where $F$ is a free monoid over a finite alphabet.
\end{theorem}

The analogous theorem for $U_l(M)$ also holds, although $F$ is unlikely to be the same monoid. This result was first proven in the 1980s by Squier in \cite{Squier1987}, with the proviso that there had to exist a special presentation for $M$ which, when viewed as a rewriting system, was itself confluent\footnote{In fact, the original condition was that $M$ had a presentation that was \dn{Church-Rosser}. It is easy to show (see e.g. \cite{Book1993}, lemma 1.1.7) that this property is equivalent to confluence.}.

This may or may not be the case even for one-relation special monoids. For example, the presentation $\langle a, b \mid abbaab = \epsilon\rangle$ is not confluent: $\underline{abbaab}baab \to baab$ and $abba\underline{abbaab} \to abba$, but both of these descendants are irreducible.

\paradec

Recall from \cref{sec:group-of-units} the definition $I = L(E(M)) \setminus \{\epsilon\}$, and define $I_0$ to be the set of all words in $I \setminus I^2$ which are irreducible with respect to our rewriting system $R$. (Here $I^2$ denotes all the concatenations of two words from $I$; that is, $I^2 = \{ uv \mid u, v \in I \}$.)

Our presentation for the group of units of $M$ was $G(M) = \langle B \mid \phi(w) = \epsilon \rangle$. We define a new alphabet $C = B \cup \{c_1, \ldots, c_m\}$ disjoint with $A$ where the new letters $c_i$ correspond to those words in $I_0$ which are not congruent to any minimal factor of $w$. There is then a natural bijection $\bar\psi : I_0 \to C$ extending the map $\bar\phi : E(M) \to B$ from \cref{sec:defining-presentation}; as in that section, we extend this to an isomorphism $\psi : I_0^* \to C^*$. Finally, we use this to define a new monoid $N = \langle C \mid \phi(w) = \epsilon\rangle$.

We claim that $I_0$ forms a generating set for the submonoid of right units.

\begin{lemma} \label{lma:I0*-generates-Ur}
	The words in $I_0$ generate $U_r(M)$.
\end{lemma}
\begin{proof}
	Let $u \in A^*$ be the irreducible representative (with respect to $R$) of an element of $U_r(M)$. Then by \cref{lma:factor-I*}, $u \in I^*$. The set $I_0$ consists of the irreducible words in $I \setminus I^2$; since $u$ is irreducible, and $(I^2)^* \subseteq I^*$, $u$ belongs to $I_0^*$.

	Conversely, if $v \in I_0$, then either $v \in E(M)$ --- in which case it is a unit and so certainly a right unit --- or it is a left factor of some element $v' \in E(M)$. Then $vv'$ is a unit, and so there is some $v'' \in A^*$ such that $v'v''$ is a right inverse for $v$, meaning $v$ is in $U_r(M)$. Every generator of $I_0^*$ is hence right invertible, and so every element of $I_0^*$ must be.
\end{proof}

We will now use $\psi$ to construct a map from $N$ to the group of right units and claim it is an isomorphism. As in \cref{sec:group-of-units}, the proof of this relies crucially on the fact that $\psi$ is `compatible' with the congruences defining $M$ and $N$. To show this is the case, we require the following, rather technical, factorisation theorem for special presentations.

\newcommand{\verteq}{\rotatebox{90}{$=$\hspace{0.5em}}}
\newcommand{\verteqM}{\updownarrow}
\begin{lemma} \label{lma:special-factorisation}
	Let $M = \langle A \mid w = \epsilon\rangle$ be a special monoid,  and let $u, v \in A^+$ such that $u =_M v$. Then there are words $u_1, \ldots, u_n, v_1, \ldots v_n \in A^*$ and $x_1, \ldots, x_n \in A^+$ into which $u$ and $v$ factor as
		\[
		\arraycolsep=0.2em
		\begin{array}{ccccccccc}
			u =& u_0 & x_1 & u_1 & x_2 & u_2 & \cdots & x_n & u_n \\
			& \verteqM & \verteq & \verteqM & \verteq & \verteqM & & \verteq & \verteqM \\
			v =& v_0 & x_1 & v_1 & x_2 & v_2 & \cdots & x_n & v_n
		\end{array}
		\]
	where $\leftrightarrow$ denotes equality in $M$, $u_i$ and $v_i$ are invertible in $M$ for every index $i$, and $u_j v_j \ne \epsilon$ for every index $0 \le j \le n - 1$.
\end{lemma}

This is a weakening of theorem 1.2 in \cite{Zhang1992}, for which Zhang refers the reader to \S5 of \cite{Otto1991} for a proof (although this paper still does not give a full proof). If we require a stricter condition on the $u_i$ and $v_i$, namely that they are so-called `maximal' invertible factors of $u$ and $v$, then the factorisation is in fact unique --- however, we shall not require this property to show the results in this section.

\begin{lemma}
	Let $s, x$ be words in $A^*$ such that both $s \in I_0$ and $xs \in I_0$. Then $x = \epsilon$. \label{lma:I0-suffix-code}
\end{lemma}
\begin{proof}
	Recall that $I_0 \subseteq I \setminus I^2 \subseteq I = L(E(M)) \setminus \{\epsilon\}$. We cannot have $x \in I_0$, because then $xs \in I_0^2$, contradicting $I_0$ being disjoint from $I^2$. But $xs$ is a proper left factor of a word in $E(M)$, and so $x$ is certainly a left factor of a word in $E(M)$. We know it is not in $I$, so the only remaining possibility is that $x = \epsilon$.
\end{proof}

\begin{prop}
	If $u, v \in I_0^*$, then $u =_M v$ if and only if $\psi(u) =_N \psi(v)$. \label{prop:psi-MN-compatible}
\end{prop}
\begin{proof}
	If $\psi(u) =_N \psi(v)$, then a very similar argument to \cref{prop:phi-compatible-MM'} gives $u =_M v$, noting that since $w \in E(M)^*$, $\psi(w) = \phi(w) = \epsilon$.

	Conversely, suppose $u =_M v$. If both $u$ and $v$ are invertible, then they belong to $E(M)^*$, and so $\psi(u) = \phi(u)$ and $\psi(v) = \phi(v)$. Hence by \cref{prop:phi-compatible-MM'}, $\psi(u) =_M \psi(v)$.

	If at least one is not invertible, then we induct on the total length $|u| + |v|$ of the strings and take advantage of our factorisation result above. If $|u|+|v| = 0$, then $u = v = \epsilon$ and so trivially $\psi(u) =_N \psi(v)$. So suppose the proposition holds for all pairs of words whose total length is less than $|u| + |v|$, and let $u_1, \ldots, u_n, v_1, \ldots, v_n$ and $x_1, \ldots, x_n$ give a factorisation of $u$ and $v$ as in \cref{lma:special-factorisation}.

	We consider two cases. In the first case, we suppose at least one of $u_n$ or $v_n$ is nonempty; assume without loss of generality that $u_n \ne \epsilon$. Then by the factorisation lemma, $u_n$ is invertible, and so by \cref{lma:I0*-generates-Ur}, $u_n \in I_0^*$. For $u$ to be in $I_0^*$ as the hypothesis claims, it must then also be the case that $u_0x_1u_1\cdots x_n \in I_0^*$. Since $u_n =_M v_n$, $v_n$ is also invertible in $M$ and a similar argument gives $v_0x_1v_1\cdots x_n \in I_0^*$. Bringing this together,
	\begin{align*}
		u_0x_1u_1 \cdots x_n u_n &=_M v_0x_1v_1\cdots x_n v_n \\
		&=_M v_0x_1v_1\cdots x_n u_n
	\end{align*}
	and so right multiplying by the inverse of $u_n$ gives
		\[ u_0x_1u_1 \cdots x_n =_M v_0x_1v_1\cdots x_n. \]
	The total length of the strings on each side is less than $|u| + |v|$ because $u_n$ is nonempty, so by the inductive hypothesis,
		\[ \psi(u_0x_1u_1 \cdots x_n) =_N \psi(v_0x_1v_1\cdots x_n). \]
	Then multiplying again gives
	\begin{align*}
		\psi(u_0x_1u_1 \cdots x_n)\psi(u_n) &=_N \psi(v_0x_1v_1\cdots x_n)\psi(u_n) \\
		&=_N \psi(v_0x_1v_1\cdots x_n)\psi(v_n).
	\end{align*}
	The last equivalence holds from our earlier argument, because $u_n =_M v_n$, and both are invertible. We know that all the arguments to $\psi$ in the above equation belong to $I_0^*$, and so the fact that $\psi$ is a homomorphism on $I_0^*$ allows us to conclude that
	\[ \psi(u_0x_1u_1 \cdots x_n u_n) =_N \psi(v_0 x_1 v_1 \cdots x_n v_n) \]
	as required.

	It remains to deal with the case where $u_n = v_n = \epsilon$. Factorise $u = f_1 f_2 \cdots f_l$ and $v = g_1 g_2 \cdots g_m$, where each $f_i$ and $g_i$ come from $I_0$.

	\begin{claim*}
		The factors $f_l$ and $g_m$ are equal.
	\end{claim*}
	\begin{proof}	
	If $|x_n| \ge |f_l|$, then $x_n = Ef_l$ for some $E \in A^*$. Since $u$ and $v$ both end in $x_n$, $g_m$ ends in $f_l$; then since both $f_l$ and $g_l$ are in $I_0$, by \cref{lma:I0-suffix-code}, $f_l = g_m$.

	On the other hand, if $|x_n| < |f_l|$, we claim that $f_l = Fu_k x_{k+1} \cdots x_{n-1}u_{n-1}x_n$ for some $0 \le k < n$ and a suffix $F \in A^+$ of $x_{k-1}$. Since it is longer than $x_n$, it must contain at least part of $u_{n-1}$, and perhaps contains more of $u$. However, if it begins with just part of some $u_k$, it must contain all of it: if $u = u_k'u_k''$ and $f_l = u_k''\omega$ for $u_k', u_k'', \omega \in A^+$, then since $u_k$ is invertible, there is a $\overline{u_k}$ such that $f_l =_M \overline{u_k}u_k' \cdot u_k''\omega =_M \omega$. So $f_l \leftrightst_R \omega$. But $f_l$ is in $I_0$ and so is irreducible by $R$, hence $\omega \to^*_R f_l$; by the definition of $R$, this gives $|\omega| \ge |f_l|$, which is a contradiction.

		By the same argument, $w_m = Gv_jx_{j+1} \cdots x_{n-1}v_{n-1}x_n$ for some $0 \le j < n$ and a suffix $G \in A^+$ of $x_{j-1}$. We may assume that $u$ and $v$ are such that $j \le k$. Since $f_l$ and $g_m$ are irreducible under $R$, all the $u_p$ contained in $f_l$ are irreducible under $R$, for $k \le p < n$; as are all the $v_q$ are for $j \le q < n$. The factorisation guarantees that $u_i =_M v_i$ for $k \le i < n$, and so $u_i \leftrightst_{\{w\to\epsilon\}} v_i$. So $u_i = v_i$ for all these $i$, and hence $f_l$ is a (not necessarily proper) suffix of $g_m$. Therefore by \cref{lma:I0-suffix-code}, $g_m = f_l$.
	\end{proof}

	Our situation then looks like
		\[ u =  u_0x_1u_1\cdots u_{n-1}E \cdot f_l = f_1f_2\cdots f_{l-1} \cdot f_l \stackrel{(\star)\hphantom{{}_M}}{=_M} g_1g_2\cdots g_{m-1} \cdot f_l = v_0x_1v_1\cdots v_{n-1}E \cdot f_l = v. \]
	Since $f_l \in I_0$, it is a right unit by \cref{lma:I0*-generates-Ur}; multiplying $(\star)$ by its right inverse gives
		\[ f_1f_2\cdots f_{l-1} =_M g_1g_2\cdots g_{m-1}. \]
	The string $f_l$ is nonempty, so by the inductive hypothesis, we conclude
		\[ \psi(f_1 f_2 \cdots f_{l-1}) =_N \psi(g_1 g_2\cdots g_{m-1}). \]
	Our words here are all in $I_0^*$, so we can multiply to get
		\[ \psi(f_1 f_2 \cdots f_{l-1} f_l) =_N \psi(g_1 g_2\cdots g_{m-1} g_m); \]
	that is, $\psi(u) =_N \psi(v)$ as required.
\end{proof}


We now refine \cref{thm:gen-units-factor-freely} as follows:

\begin{theorem} \label{thm:spec-units-factor-freely}
	The monoid $N$ is in fact the submonoid of right units of $M$, i.e. $U_r(M) \cong \langle C \mid \phi(w) = \epsilon \rangle = G(M) \ast \langle C \setminus B \mid \rangle$.
\end{theorem}
\begin{proof}
	Let $\rho_M$ and $\rho_N$ be the congruences on $A^*$ and $C^*$ associated with the presentations $M = \langle A \mid w = \epsilon \rangle$ and $N = \langle C \mid \psi(w) = \epsilon\rangle$ respectively.
	Define a map
		\begin{align*}
			\xi : U_r(M) &\to N \\
			 u/\rho_M &\mapsto \psi(u)/\rho_N
		\end{align*}
	where $u$ is the irreducible representative in $I_0^*$ of any element of $U_r(M)$, which exists by \cref{lma:I0*-generates-Ur}. This map is well-defined and injective by \cref{prop:psi-MN-compatible}, and it is a surjective homomorphism because $\psi$ is.
\end{proof}

A symmetrical argument, which we shall not attempt to write out in full, gives us the theorem in the other direction:
\begin{theorem}
	The submonoid $U_l(M)$ of left units of $M$ is isomorphic to the free product of $G(M)$ and a free monoid over a finite generating set.
\end{theorem}

\begin{onlycomputing}
\section{Computing with presentations}

We formalise the algorithm from \cref{sec:special-monoids} as follows:

\begin{algorithm} Compute a presentation for the group of units of a one-relation special monoid: \label{alg:G-presentation}
\hspace{0.05\textwidth}
\parbox[t]{0.9\textwidth}{
	\textbf{Input:} a finite monoid presentation $M = \langle A \mid w = \epsilon \rangle$, $w \in A^*$ \\
	\textbf{Output:} a generating set $E(M)$ for the group of units of $\Mon \langle A \mid w \rangle$
	\medskip

	\begin{enumerate}
		\item Put:
			\begin{flalign*}
				\hspace{1cm} B &\leftarrow \emptyset & \\
				C_i &\leftarrow \emptyset \\
				C_{i+1} &\leftarrow \{w\}
			\end{flalign*}
		\item While $C_i \ne C_{i+1}$:
			\begin{enumerate}
				\item Put:
					\begin{flalign*}
						\hspace{1cm} L &\leftarrow \emptyset &\\
						R &\leftarrow \emptyset \\
						C_i &\leftarrow C_{i+1}
					\end{flalign*}
				\item For each word $v$ in $C_i$:
					\begin{enumerate}
						\item Compute the prefixes of $v$, including $\epsilon$ and $v$, and add them to $L$
						\item Compute the suffixes of $v$, including $\epsilon$ and $v$, and add them to $R$
					\end{enumerate}
				\item For each word $y \in W = L \cap R$ and each word $x \in C_i$:
					\begin{enumerate}
						\item If $y_1 y_2 \cdots y_{|y|} x_{|y|} x_{|y|+1} \cdots x_{|w|} \in C_i$, then add $x_{|y|} \cdots x_{|w|} y_1 \cdots y_{|y|}$ to $C_{i+1}$
						\item If $x_1 x_2 \cdots x_{|w|-|y|}$$ y_{1} y_2$$\cdots y_{|y|}$$ \in C_i$, then add $y_1$$y_2 \cdots y_{|y|}$$x_1 x_2$$\cdots$$x_{|w|-|y|}$ to $C_{i+1}$
					\end{enumerate}
			\end{enumerate}
		\item Output $E(M) = C_{i+1}$
	\end{enumerate}
}
\end{algorithm}

In \cref{sec:constructing-genset}, we argued that this algorithm terminates for all input presentations, say after $k$ iterations. We also argued in \cref{sec:group-of-units} that its output indeed correctly generates the group of units of the monoid with the given presentation.

Here, we show that this algorithm allows us to deduce some properties of this group and perform some numerical computations.

\subsection{Properties of the group of units}

The key theorems on which these computations rely are the following:

\begin{theorem}
	The monoid $M = \Mon \langle A \mid w = \epsilon \rangle$ is a group if and only if $A \subseteq E(M)$. \incomplete
\end{theorem}
\begin{proof}
	Suppose $A \subseteq E(M)$. Then every element of $M$ can be expressed as a product of elements in $E(M)$, and so the isomorphism $\phi : E(M)^* \to G(M)$ from \cref{thm:Mdash-is-group-of-units} induces an isomorphism from $M$ to $G(M)$ and hence $M$ is a group.

	To show the converse, we consider the contrapositive. Suppose $A \not\subseteq E(M)$. Then there exists an element $x \in A$ such that $x \not\in E(M)$. If this element is not invertible, then $M$ is not a group, so assume that it is. Since $x$ is invertible, by the proof of \cref{thm:Mdash-is-group-of-units} it must be a product $x_1 \cdots x_n$ of elements in $E(M)$.
\end{proof}

\begin{theorem}
	The monoid $M = \Mon \langle A \mid w = \epsilon \rangle$ has trivial group of units if and only if $E(M) = \{w\}$.
\end{theorem}
\begin{proof}
	If $E(M) = \{w\}$, then by \cref{thm:Mdash-is-group-of-units}, $G(M) \cong \langle w\phi \mid w\phi = \epsilon \rangle$ which is clearly trivial.

	Conversely, if $G(M)$ is trivial, then in any presentation for $G(M)$, all generators must be trivial. In particular this is true of the presentation $\langle B \mid \phi(w) = \epsilon\rangle$, so every letter in $B$ is trivial, and hence every word in $E(M)$ is trivial in $M$. 
\end{proof}
\end{onlycomputing}



\section{Inverse monoids} \label{sec:inverse-monoids}

In this section, we will describe how the word problem for one-relation special monoids fits together with other work on the general word problem for semigroups. In particular, we will focus on one more special case, the word problem for one-relation special inverse monoids, whose word problem has been shown to be equivalent to that of a general one-relation monoid.

\subsection{Reductions of the one-relation semigroup problem}
Many of the first positive results on the word problem for one-relation semigroups were first shown by Adjan from the 1960s, including the special case $M = \Mon \langle A \mid w = \epsilon\rangle$ considered in the previous section, in \cite{Adian1966}. Another important special case considered in this monograph, which did not rely on the semigroup having a monoid structure, is that of a semigroup $S = \Sgp \langle A \mid u = v\rangle$, where the words $u$ and $v$ have different first and last letters. The word problem is indeed decidable for such a semigroup; Adjan showed this by demonstrating that $S$ can be embedded into the group $\Gp \langle A \mid u = v \rangle$ with the same presentation, with the result then following by Magnus' theorem (\cref{thm:orgp-decidablewp}).

In both cases, as we saw in \cref{sec:special-monoids}, the solutions reduce the word problem of the semigroup to a similar problem for groups.

Another set of results in a similar vain, due to a variety of authors, reduce the general word problem for semigroups to various special cases, in the hopes that these might be more tractable. One such reduction was proven by Adjan and Oganesyan in the 1980s \cite{Adyan1987}:

\begin{theorem}[Adjan, Oganesyan] \label{thm:aua=bva}
	The word problem is decidable for all one-relation semigroups if it is decidable for those with presentations of the form $\Sgp \langle a, b \mid aua = bva \rangle$, where $u, v \in \{a, b\}^*$.
\end{theorem}

Building on Adjan and Oganesyan's reduction, Ivanov, Margolis and Meakin \cite{Ivanov2001} showed more recently that the one-relation semigroup word problem is solved if the one-relation special inverse monoid word problem is solved; that is, if the word problem is decidable for inverse monoids with presentations of the form $\Inv \langle A \mid w = \epsilon\rangle$. 

We will examine this result in more detail in the following sections. Our particular motivation for doing so is an observation of the former that a similar set to the one found to generate $G(M)$ in \cref{sec:special-monoids} also suffices to generate the group of units of an inverse monoid (although a full presentation is not derived). In understanding the group of units of the special monoid $M$, we were able to solve the word problem for the whole monoid. It seems reasonable that better understanding the group of units in the inverse monoid case could lead to a solution for their word problem, and therefore for the general one-relation semigroup word problem.

\subsection{Inverse semigroups and monoids}

We begin with an elementary discussion of inverse semigroups and monoids. More thorough treatment is found in, for example, chapter 5 of \cite{Howie1995}.

\begin{defn}
	Let $S$ be a semigroup, and $x \in S$. Then an element $y \in S$ is a \dn{(semigroup) inverse} for $x$ if $xyx = x$ and $yxy = y$.
\end{defn}

Note that in general, semigroup inverses are not unique even when they exist. If every $x \in S$ has an inverse, $S$ is called a \dn{regular semigroup}. Furthermore:

\begin{defn}
	If every element $x \in S$ has a \emph{unique} semigroup inverse $x^{-1} \in S$, then $S$ is called an \dn{inverse semigroup}. If $S$ also possesses an identity element, then $S$ is said to be an \dn{inverse monoid}.
\end{defn}

It is clear that every group $G$, for example, is an inverse monoid; since if $x^{-1}$ is the (group) inverse for an element $x \in G$, it is also the unique semigroup inverse in $G$. However, not every inverse monoid is a group:

\begin{example}
The bicyclic monoid, presented by $\Mon \langle b, c \mid bc = \epsilon \rangle$  is inverse: $b\cdot c\cdot b = b$ and $c\cdot b \cdot c = c$. But it is not a group, since while $bc = \epsilon$, $cb \ne \epsilon$.
\end{example}

Our usual notion of semigroup presentations extends to inverse monoids in a relatively natural way. Recall that if $A$ is an alphabet, we write $A^{-1}$ for the set of formal inverses of letters in $A$: that is, $A^{-1}$ is a set disjoint from $A$ such that there is a bijection $a \mapsto a^{-1}$ from $A$ to $A^{-1}$. For concision, we write $\Abar$ for $A \cup A^{-1}$.

\begin{defn}
	Let $\Mon \langle A \mid R \rangle$ be a monoid presentation. Then the \dn{inverse monoid presented by $\langle A \mid R \rangle$} is the monoid
	\begin{align*}
		\Inv \langle A \mid R \rangle = \Mon \langle \Abar \mid R &\cup \{ aa^{-1}a = a : a \in \Abar^* \} \\
		&\cup \{ aa^{-1}bb^{-1} = bb^{-1}aa^{-1} : a, b \in \Abar^* \}\rangle,
	\end{align*}
	where we define the inverse $u^{-1}$ of a word $u = u_1u_2\cdots u_n \in (A \cup A^{-1})^*$ to be $u^{-1} = u_n^{-1} u_{n-1}^{-1} \cdots u_1^{-1}$ as one would expect.
\end{defn}

The least congruence containing the relations described above (i.e. the congruence associated with the free inverse semigroup $\Inv \langle A \mid\rangle$) is known as the \dn{Wagner congruence}, after Viktor Wagner, one of the first mathematicians to investigate inverse semigroups in the 1950s.

This definition arises from the following characterisation of inverse semigroups:
\begin{theorem} \label{thm:inv-semigp-cond}
	A semigroup $S$ is an inverse semigroup if and only if it admits a map $a \mapsto a^{-1}$ from $S$ to $S$, such that $(a^{-1})^{-1} = a$, $aa^{-1}a = a$ and $aa^{-1}bb^{-1} = bb^{-1}aa^{-1}$ for all $a, b \in S$.
\end{theorem}

We give a proof of the forwards direction as motivation, adapted from theorem 5.1.1 in \cite{Howie1995} (although note that Howie uses slightly different terminology), but do not show the reverse implication here.

\begin{proof}[ \pCref{thm:inv-semigp-cond}]
	Suppose $S$ is an inverse semigroup. Clearly the map taking $x \in S$ to its unique inverse satisfies the first two properties required, so we show the third. Let $a, b \in S$, $e = aa^{-1}$, $f = bb^{-1}$ and $z = (ef)^{-1}$. Calculating,
	\[ (ef)fze(ef) = ef^2ze^2f = efzef = (ef)z(ef) = ef, \]
	and
	\[ (fze)ef(fze) = fze^2f^2ze = f(z\cdot ef\cdot z)f = fze, \]
	so $fze$ is an inverse of $ef$. So by the uniqueness of inverses, $z = fze$. But then
	\[ z^2 = (fze)^2 = f(z\cdot ef \cdot z)e = fze = z. \]
	Hence $z\cdot z\cdot z = z$, i.e. $z$ is its own inverse. So $z = z^{-1} = ((ef)^{-1})^{-1} = ef$, which also gives $(ef)^{-1} = ef$ and $(ef)^2 = ef$. A similar argument showing $(fe)ezf(fe) = (fe)z(fe)$ and $(ezf)fe(ezf) = ezf$ allows us to conclude that $(fe)^2 = fe$ also. Then finally,
	\[ (ef)fe(ef) = ef^2e^2f = efef = ef \]
	and
	\[ (fe)ef(fe) = fe^2f^2e = fefe = fe, \]
	so $fe$ as well as $ef$ are inverses of $ef$. Therefore by uniqueness of inverses, $aa^{-1}bb^{-1} = ef = fe = bb^{-1}aa^{-1}$ as required.
\end{proof}

Our final definition is that of a reduced word.

\begin{defn}
	A word $w \in \Abar^*$ is \dn{reduced} if it does not contain $xx^{-1}x$ or $x^{-1}xx^{-1}$ for any $x \in A$. Moreover, a word $w$ is \dn{cyclically reduced} if all cyclic permutations of $w$ are reduced.
\end{defn}

Observe that in fact the rewriting system $R_F = \{ xx^{-1}x \to x, x^{-1}xx^{-1} \to x^{-1} \mid x \in A\}$ is confluent since $\underline{x^{-1}xx^{-1}}x \to x^{-1}x \leftarrow x^{-1}\underline{xx^{-1}x}$ is the only overlap between each pair of rules for a given $x$, and rules for different $x \in A$ cannot overlap. This rewriting system is also noetherian, since every rule reduces the length of the string.

\paradec
For some basic examples, consider the bicyclic monoid is given by the presentation $B = \Inv \langle a \mid aa^{-1} = \epsilon \rangle$. The monoid of integers under addition, also known as the free inverse monoid on one generator, is presented by $\mathbb{Z} = \Inv \langle a \mid \rangle$. (This is also a group presentation for $\mathbb{Z}$.)

The canonical examples of inverse monoids, however, are the symmetric inverse monoids, the monoids of all partial bijections from a set to itself.

\begin{defn}
	A \dn{partial bijection} from a set $X$ to a set $Y$ is a partial function from $X$ to $Y$ which is a bijection from a subset of $X$ to a subset of $Y$. The \dn{symmetric inverse monoid} on a set $X$, denoted $\mathcal{I}_X$, is the set of all partial bijections from $X$ to $X$, where the operation is taken to be composition of relations.
\end{defn}

Their canonicity comes from the following theorem (see chapter 5 of \cite{Howie1995}), the analogue of Cayley's theorem for groups:
\begin{theorem}[Wagner-Preston]
	Every inverse monoid $M$ is isomorphic to an inverse submonoid of $\mathcal{I}_M$.
\end{theorem}

We write partial bijections in two-line notation, using `$-$' to denote that the map is undefined at that point. If we take our set $X$ to be just $\{0, 1\}$, we get the following collection of maps:
	\[
		\mathcal{I}_{\{0,1\}} = \left\{ \pmat{0 & 1 \\ - & -}, \pmat{0 & 1 \\ 0 & -}, \pmat{0 & 1 \\ 1 & -}, \pmat{0 & 1 \\ - & 0}, \pmat{0 & 1 \\ - & 1}, \pmat{0 & 1 \\ 0 & 1}, \pmat{0 & 1 \\ 1 & 0} \right\}.
	\]
Composition of relations in this case corresponds to composition of functions, except that `$-$' is contagious: if $f, g$ are partial bijections and either $f$ or $g$ is undefined at a point $x$, then so is $fg$. For example, \[\pmat{0 & 1 \\ 0 & -} \pmat{0 & 1 \\ - & 1} = \pmat{0 & 1 \\ - & -}. \]
It is clear that this is an associative operation, and that the composition of two partial bijections is again a partial bijection. We also have an identity element, namely the identity map, and so $\mathcal{I}_X$ is genuinely a monoid. Inverses are obtained by considering the inverse of an element as a bijection from its domain to its image.

The inverse monoid $\mathcal{I}_{\{0,1\}}$ is in fact given by the presentation $I_{\{0,1\}} = \Inv \langle a, z \mid a^2 = \epsilon, z^2 = z, (za)^2 = (za)^3 \rangle$. Here, $a$ corresponds to the permutation $(0 1)$, and $z$ to the partial map $\left(\begin{smallmatrix} 0 & 1 \\ 1 & - \end{smallmatrix}\right)$. Enumerating words in $\{a, z\}$ and using the relations shows that the presentation gives rise to an inverse monoid of 8 elements, and the remaining relations are easily checked.

More generally (see chapter 9 of \cite{Lipscomb1996}), the symmetric inverse monoid on $\{1, \ldots, n\}$ is given by the presentation
\begin{align*}
	\mathcal{I}_n = \Inv \langle z, t_1, \ldots, t_{n-1} \mid & \quad\, \{ t_i^2 = (t_i t_{i+1})^3 = (t_i t_j)^2 = \epsilon \mid 1 \le i < n,\ |i-j|>1 \} \\
	& \cup \{ zt_i = t_iz \mid 2 \le i < n \} \cup \{ z^2 = z, (zt_1)^2 = (zt_1)^3 \} \rangle,
\end{align*}
where the first set of relations together with generators $t_1, \ldots, t_{n-1}$ suffices to define $S_n$, the symmetric group on $n$ points.


\paradec

The word problem for finitely presented inverse monoids is undecidable in general: as discussed in the introduction, Novikov and Boone showed that there exists a finitely presented group $G = \Gp \langle A \mid R \rangle$ whose word problem is undecidable. This group is also given by the finite inverse monoid presentation $\Inv \langle A \mid R \cup \{ aa^{-1} = a^{-1}a = \epsilon \} \rangle$, and so is an example of a finitely presented inverse monoid with unsolvable word problem.

As in the case of semigroups, we know some classes of inverse monoid which do have solvable word problem. We will see an example of one such class in the next section, and then consider what is currently known about one-relation inverse monoids. 

\subsection{Free inverse monoids} \label{sec:free-inverse-monoids}
Free inverse monoids are more interesting than they may appear at first glance. They have a more complicated structure than free semigroups and monoids, and their word problem is less trivial to solve: in contrast with the situation with free groups, the usual monoid presentation for free inverse monoids does not in general give a confluent, noetherian rewriting system, and so a normal form is less obvious. In this section, we will use a different approach, giving an overview of a graph-theoretic solution to the word problem first described by Munn in \cite{Munn1974}; our exposition follows this paper and Lawson in chapter 6 of \cite{Lawson1998}.

For our purposes, a \dn{graph} $G$ consists of a set of vertices $V(G)$ and a set of directed, labelled edges $E(G) \subseteq V(G) \times V(G)$. The label of an edge from $v_1 \to v_2$ is denoted $\lambda(v_1, v_2)$.

\begin{defn}
	Let $G$ be a group generated by a set of elements $A$. Then the (right) \dn{Cayley graph} of $G$ with respect to $A$, denoted $\Gamma(G, A)$, is the graph whose vertices are the elements of $G$ and where there is an edge $g \to[a] h$, for $g, h \in G$ and $a \in \Abar$, if and only if $ga =_G h$.
\end{defn}

Here is a portion of the Cayley graph of the free group $\Gp \langle {\color{red} a}, {\color{blue} b}\mid\rangle$:

	\begin{center}
	\begin{tikzpicture}%
		[vertex/.style={draw,circle,inner sep=0pt,minimum size=1cm,align=center,font=\footnotesize,node distance=2.8cm},%
		 v2/.style={vertex,node distance=1.8cm}]

		\node[vertex] (eps) at (0,0) {$\epsilon$};
		\node[vertex] (a) [above of=eps] {$a$};
		\node[vertex] (aa) [above of=a] {$a^2$};
		\node[vertex] (a') [below of=eps] {$a^{-1}$};
		\node[vertex] (a'a') [below of=a'] {$a^{-2}$};
		\node[vertex] (b') [left of=eps] {$b^{-1}$};
		\node[vertex] (b'b') [left of=b'] {$b^{-2}$};
		\node[vertex] (b) [right of=eps] {$b$};
		\node[vertex] (bb) [right of=b] {$b^2$};
		\node[v2] (ba) [above of=b] {$ba$};
		\node[v2] (ba') [below of=b] {$ba^{-1}$};
		\node[v2] (b'a) [above of=b'] {$b^{-1}a$};
		\node[v2] (b'a') [below of=b'] {$b^{-1}a^{-1}$};

		\def\aEdge#1#2{%
			\draw [->,red] (#1) to [bend left] node [midway,left] {$a$} (#2);%
			\draw [->,red] (#2) to [bend left] node [pos=0.42,right] {$a^{-1}$} (#1);%
		}
		\def\bEdge#1#2{
			\draw [->,blue] (#1) to [bend left] node [midway,above] {$b$} (#2);%
			\draw [->,blue] (#2) to [bend left] node [pos=0.42,below] {$b^{-1}$} (#1);%
		}

		\aEdge{a'a'}{a'} \aEdge{a'}{eps} \aEdge{eps}{a} \aEdge{a}{aa}
		\bEdge{b'b'}{b'} \bEdge{b'}{eps} \bEdge{eps}{b} \bEdge{b}{bb}
		\aEdge{b}{ba} \aEdge{ba'}{b}
		\aEdge{b'}{b'a} \aEdge{b'a'}{b'}

		\newcommand{\rightnub}[2][$\ldots$]{%
			\node (rnub#2) [right of=#2] {#1};%
			\draw [->,blue] (#2) to [bend left] node [midway,above] {} (rnub#2);%
			\draw [->,blue] (rnub#2) to [bend left] node [pos=0.42,below] {} (#2);%
		}
		\newcommand{\leftnub}[2][$\ldots$]{%
			\node (lnub#2) [left of=#2] {#1};%
			\draw [->,blue] (lnub#2) to [bend left] node [midway,above] {} (#2);%
			\draw [->,blue] (#2) to [bend left] node [pos=0.42,below] {} (lnub#2);%
		}
		\newcommand{\hnubs}[2][$\ldots$]{\leftnub[#1]{#2}\rightnub[#1]{#2}}
		\newcommand{\topnub}[2][$\vdots$]{
			\node (tnub#2) [above of=#2] {#1};
			\draw [->,red] (#2) to [bend left] node [midway,above] {} (tnub#2);%
			\draw [->,red] (tnub#2) to [bend left] node [pos=0.42,below] {} (#2);%
		}
		\newcommand{\bottomnub}[2][$\vdots$]{
			\node (bnub#2) [below of=#2] {#1};
			\draw [->,red] (bnub#2) to [bend left] node [midway,above] {} (#2);%
			\draw [->,red] (#2) to [bend left] node [pos=0.42,below] {} (bnub#2);%
		}
		\newcommand{\vnubs}[2][$\vdots$]{\topnub[#1]{#2}\bottomnub[#1]{#2}}

		\topnub{aa}\hnubs{aa}
		\hnubs[]{a}
		\leftnub{b'a}\rightnub[]{b'a}\topnub{b'a}
		\leftnub[]{ba}\rightnub{ba}\topnub{ba}
		\leftnub{b'b'}\vnubs{b'b'}
		\rightnub{bb}\vnubs{bb}
		\leftnub{b'a'}\rightnub[]{b'a'}\bottomnub{b'a'}
		\rightnub{ba'}\leftnub[]{ba'}\bottomnub{ba'}
		\hnubs[]{a'}
		\hnubs{a'a'}\bottomnub{a'a'}
	\end{tikzpicture}
	\end{center}

Observe that if we identify all the double edges --- if we replace every pair of edges $g \to[x] gx$ and $gx \to[x^{-1}] g$ with a single edge $g \to gx$ --- then the above Cayley graph is a tree, i.e. the graph has no cycles. It is fairly clear that this is the case for the Cayley graph of any free group (and in fact if a group has a Cayley graph which is a tree, then it must be free).


\begin{defn}
	A \dn{bi-rooted word tree} is a triple $(\alpha, T, \beta)$ where $T$ is a tree, $\alpha$ and $\beta$ are the initial and terminal vertices respectively from $V(T)$ and:
	\begin{itemize}[(i)]
		\item \emph{[Injectivity.]} No two edges entering the same vertex have the same label.
		\item \emph{[Determinism.]} No two edges leaving the same vertex have the same label.
	\end{itemize}
\end{defn}

We will use particular subgraphs of Cayley graphs on free groups, which turn out to be word trees, to solve the word problem for inverse monoids. Write $\FGamma(A)$ for $\Gamma(\Inv \langle A \mid\rangle, A)$.

\begin{defn}
	Let $u \in \Abar^*$ be a reduced word. Then the \dn{Munn tree} of $u$ is the subgraph $\MT(u)$ of $\FGamma(A)$ induced by the vertices reached by travelling along the path from $\epsilon$ labelled by $u$, with all double edges identified and all vertex labels removed, and $\epsilon$ and the last vertex in the walk relabelled $\alpha$ and $\beta$ respectively. 
\end{defn}

The Munn tree is then a bi-rooted word tree with initial vertex $\alpha$ and terminal vertex $\beta$.

For example, if we take $A = \{a, b\}$ again, $\MT(abaa^{-1}b)$ is the following:

	\begin{center}
	\begin{tikzpicture}%
		[vertex/.style={draw,circle,inner sep=0pt,minimum size=1cm,align=center,font=\footnotesize,node distance=2.8cm}]

		\node[vertex] (eps) at (0,0) {$\alpha$};
		\node[vertex] (a) [above of=eps] {};
		\node[vertex] (ab) [right of=a] {};
		\node[vertex] (aba) [above of=ab] {};
		\node[vertex] (abb) [right of=ab] {$\beta$};

		\def\aEdge#1#2{%
			\draw [->,red] (#1) to node [midway,left] {$a$} (#2);%
		}
		\def\bEdge#1#2{
			\draw [->,blue] (#1) to node [midway,above] {$b$} (#2);%
		}
		\aEdge{eps}{a} \aEdge{ab}{aba}
		\bEdge{a}{ab} \bEdge{ab}{abb}
	\end{tikzpicture}
	\end{center}

We will reduce the question `does $u = v$ in $\Inv \langle A \mid\rangle$?' to deciding whether the Munn trees $\MT(u)$ and $\MT(v)$ are isomorphic.

\begin{defn} \label{def:graph-isomorphism}
	Let $G$ and $H$ be graphs. Then a map $\phi : V(G) \to V(H)$ is an \dn{isomorphism} if:
	\begin{enumerate}[(i)]
		\item $\phi$ is a bijection,
		\item $(u, v) \in E(G)$ if and only if $(\phi(u), \phi(v)) \in E(H)$,
		\item and $\lambda_G(u, v) = \lambda_H(\phi(u), \phi(v))$ for all $(u, v) \in E(G)$.
	\end{enumerate}
	If such a map exists, $G$ and $H$ are said to be \dn{isomorphic}.
\end{defn}

One direction is easy:

\begin{prop}
	Let $u, v \in F = \Inv \langle A \mid\rangle$. Then if $u =_F v$, $\MT(u) = \MT(v)$.
\end{prop}
\begin{proof}
	Let $u, v \in \FGamma(A)$. It suffices to show that $\MT(u) = \MT(uu^{-1}u)$ and $\MT(uu^{-1}vv^{-1}) = \MT(vv^{-1}uu^{-1})$ for arbitrary $u$ and $v$ --- if these hold, then the proposition follows from the presentation for $F$ by induction on the length of the derivation $u \leftrightst_{F} v$.

	The tree $\MT(u)$ corresponds to a path $\epsilon = x_1 \to[a_1] x_2 \to[a_2] \cdots \to[a_{n-1}] x_n =_F u$ in $\FGamma(A)$. By construction, $\MT(uu^{-1}u)$ corresponds to the path $\epsilon = x_1 \to[a_1] \cdots \to[a_{n-1}] \to x_n \to[a_{n-1}^{-1}] x_{n-1} \to[a_{n-2}^{-1}] \cdots \to[a_1^{-1}] \epsilon \to[a_1] \cdots \to[a_{n-1}] x_n$ in $\FGamma(A)$. Observe that we have not visited any vertices, or travelled along any edges, that we did not visit or travel along in constructing $\MT(u)$. Furthermore, the initial and terminal vertices $\alpha$ and $\beta$ in $\MT(uu^{-1}u)$ are exactly the vertices in $\MT(u)$ corresponding to $\epsilon$ and $x_n$. So in fact we have $\MT(u) = \MT(uu^{-1}u)$.

	Rather similarly, the vertices and edges considered when constructing $\MT(uu^{-1}vv^{-1})$ and $\MT(vv^{-1}uu^{-1})$ do not change: we follow the paths labelled $uu^{-1}$ and $vv^{-1}$ in both cases, just in a different order. Our initial and terminal vertices both correspond to $\epsilon$, and so $\MT(uu^{-1}vv^{-1}) = \MT(vv^{-1}uu^{-1})$.
\end{proof}

The converse is more difficult to establish.
\begin{prop}
	Let $F = \Inv \langle A \mid\rangle$ and $u, v \in \Abar^*$. Then if $\MT(u)$ and $\MT(v)$ are isomorphic, $u =_F v$.\label{prop:MT-isomorphic-u=Fv}
\end{prop}
We offer only a sketch of the proof here. Munn shows that there is a bijection between the isomorphism classes of bi-rooted word trees and the elements of $F$. He shows that, if two paths in a given bi-rooted word tree $T$ start at $\alpha$, finish at $\beta$ and visit every vertex, then the words which label them are equivalent in $F$; call the element they represent $f(T)$. He then establishes that if two word trees $T$ and $T'$ are isomorphic, with same initial and terminal vertices, then $f(T) = f(T')$. Finally, the above construction gives us a bi-rooted word tree $\MT(u)$ with $f(\MT(u)) =_F u$ for every word $u \in \Abar^*$, so we have a bijection $\phi$ mapping isomorphism classes of bi-rooted word trees to elements of $F$.

\begin{comment}
\begin{defn}
	Let $M(A)$ be the set of all triples $(\alpha, T, \beta)$, where $T$ is the Munn tree $\MT(u)$ for some reduced word $u \in \Abar^*$ and $\alpha, \beta \in V(T)$. We make $M(A)$ a monoid by equipping it with the multiplication
		\[ (\alpha, T, \beta)(\alpha', T', \beta') = (\alpha, U, \beta'), \]
	where $U$ is the tree obtained by joining $T$ and $T'$ identifying $\alpha$ and $\alpha'$, and then identifying any vertices $v \in V(T)$ and $v' \in V(T')$ if the path from $\alpha$ to $v$ in $T$ is isomorphic to the path from $\alpha'$ to $v'$ in $T'$.
\end{defn}

\begin{example}
	Consider the trees $T = (\alpha, \MT(abaa^{-1}b), \beta)$ from before and $T' = (\alpha', \MT(abab), \beta')$:

	\begin{center}
	\begin{tikzpicture}%
		[vertex/.style={draw,circle,inner sep=0pt,minimum size=1cm,align=center,font=\footnotesize,node distance=2.8cm}]

		\node[vertex] (eps) at (0,0) {$\alpha'$};
		\node[vertex] (a) [above of=eps] {};
		\node[vertex] (ab) [right of=a] {};
		\node[vertex] (aba) [above of=ab] {};
		\node[vertex] (abab) [right of=aba] {$\beta'$};

		\def\aEdge#1#2{%
			\draw [->,red] (#1) to node [midway,left] {$a$} (#2);%
		}
		\def\bEdge#1#2{
			\draw [->,blue] (#1) to node [midway,above] {$b$} (#2);%
		}
		\aEdge{eps}{a} \aEdge{ab}{aba}
		\bEdge{a}{ab} \bEdge{aba}{abab}
	\end{tikzpicture}
	\end{center}

	In this case, the product $TT'$ is the following:

	\begin{center}
	\begin{tikzpicture}%
		[vertex/.style={draw,circle,inner sep=0pt,minimum size=1cm,align=center,font=\footnotesize,node distance=2.8cm}]

		\node[vertex] (eps) at (0,0) {$\alpha$};
		\node[vertex] (a) [above of=eps] {};
		\node[vertex] (ab) [right of=a] {};
		\node[vertex] (aba) [above of=ab] {};
		\node[vertex] (abab) [right of=aba] {$\beta'$};
		\node[vertex] (abb) [right of=ab] {};

		\def\aEdge#1#2{%
			\draw [->,red] (#1) to node [midway,left] {$a$} (#2);%
		}
		\def\bEdge#1#2{
			\draw [->,blue] (#1) to node [midway,above] {$b$} (#2);%
		}
		\aEdge{eps}{a} \aEdge{ab}{aba}
		\bEdge{a}{ab} \bEdge{aba}{abab} \bEdge{ab}{abb}
	\end{tikzpicture}
	\end{center}
\end{example}

\begin{theorem} \label{thm:equal-FIM-iff-Munn-isomorphic}
	Let $u, v \in F = \Inv \langle A\mid\rangle$. Then $u =_F v$ if and only if $\MT(u)$ and $\MT(v)$ are isomorphic as birooted trees, i.e. they are isomorphic as graphs and vertices labelled $\alpha$ and $\beta$ in $\MT(u)$ have their images labelled $\alpha$ and $\beta$ in $\MT(v)$ under $\phi$.
\end{theorem}
\end{comment}

Taking together these two propositions gives us the key result:

\begin{theorem}
	The word problem for free inverse monoids is decidable.
\end{theorem}
\begin{proof}
	Suppose $F = \Inv \langle A \mid\rangle$, and let $u, v \in \Abar^*$. By \cref{prop:MT-isomorphic-u=Fv}, $u =_F v$ if and only if $\phi^{-1})(u)$ and $\phi^{-1}(v)$ are equal. We can construct a representative from each isomorphism class, namely $\MT(u)$ and $\MT(v)$, in a finite number of steps. From there, determining when two finite graphs are isomorphic is a well-studied problem; it is easily seen to be decidable --- there are a finite number of possible maps $\phi : V(G) \to V(H)$, and only finitely many conditions to check as per \cref{def:graph-isomorphism}. Every Munn tree is finite, so it is decidable whether $\MT(u)$ and $\MT(v)$ are isomorphic, so it is decidable whether $\phi^{-1}(u) = \phi^{-1}(v)$ and in turn whether $u =_F v$..
\end{proof}

\subsection{Special inverse monoids and their groups of units}

Analogously to our definition from \cref{sec:one-relation-overview}, we consider the following class of inverse monoids:
\begin{defn}
	Let $M$ be an inverse monoid. Then $M$ is said to be a \dn{special inverse monoid} if it admits a presentation of the form $M = \Inv \langle A \mid w_1 = \epsilon, w_2 = \epsilon, \ldots, w_n = \epsilon \rangle$ for some $w_i \in \Abar^*$.
\end{defn}

As discussed in the introduction to this section, we are considering inverse monoids primarily because of the following result:
\begin{theorem}[\cite{Ivanov2001}, Theorem 2.2]
	If the word problem is decidable for one-relation special inverse monoids $M = \Inv \langle A \mid w = \epsilon\rangle$, where $w \in \Abar^*$ is reduced, then the word problem is decidable for all one-relation monoids.
\end{theorem}

Ivanov, et al. assert that the word problem for the class of semigroups described in \cref{thm:aua=bva} is reducible to that for monoids $M$ with presentations of the form $\Mon \langle A \mid aub = avc \rangle$, for $a, b, c \in A$, $b \ne c$ and $u, v \in A^*$. They then show that this monoid embeds in the inverse monoid $I = \Inv \langle A \mid aubc^{-1}v^{-1}a^{-1} = \epsilon\rangle$, and so if the word problem were solvable for all one-relation special inverse monoids, it would be for $I$ and hence $M$.


Motivation in hand, we reproduce their result on the group of units of a special inverse monoid, which has an interesting connection to the discussion in \cref{sec:special-monoids}. They make the following definitions:

\begin{defn}
	If $w, w' \in \Abar^*$, then $w'$ is a \dn{cyclic conjugate} of $w$ if $w' = uv$ and $w = vu$ for some factors $u, v \in \Abar^*$. Furthermore, $w'$ is a \dn{unit cyclic conjugate} with respect to a presentation $M = \Inv \langle A \mid w_1 = \epsilon, \ldots, w_n = \epsilon \rangle$ if $w'$ is a cyclic conjugate of some $w_i$ and $w' =_M \epsilon$.
\end{defn}

Observe that, if we take the same definition but consider monoid presentations rather than inverse monoid presentations, every element of the set $C_k$ from \cref{sec:constructing-genset} is a unit cyclic conjugate of $w$ with respect to $M = \Mon \langle A \mid w = \epsilon \rangle$ --- by construction every element is a cyclic conjugate, and each one is trivial in $M$ by the proof of \cref{prop:M'-is-group}.

The generation theorem is then as follows:

\begin{theorem}[\cite{Ivanov2001}, Proposition 4.2] \label{thm:inv-monoid-units-unit-conjugates}
	Let $M = \Inv \langle A \mid w_1 = \epsilon, \ldots, w_n = \epsilon\rangle$, where each $w_i$ is cyclically reduced. Then the group of units of $M$ is the submonoid generated by suffixes of the unit cyclic conjugates of each relator $w_i$.
\end{theorem}

Translating the language again, we see that the generating set is analogous to $E(M)$ --- every word in $E(M)$ is a suffix of a unit cyclic conjugate.

\Cref{thm:inv-monoid-units-unit-conjugates} is argued in a broadly similar way to \cref{thm:Mdash-is-group-of-units}. First, it is established that every right unit can be written as a product of prefixes of the relators $w_i$, similarly to \cref{lma:factor-I*}. Then, a similar induction to the body of \cref{thm:Mdash-is-group-of-units} finishes the proof, as their treatment is less formal with regards to congruence classes and so on than our description.


\subsection{Some inverse monoids with solvable word problem}

One of the highlights of the paper \cite{Ivanov2001} that we have been discussing is the following result:
\begin{defn}
	A group presentation $\Gp \langle A \mid w = \epsilon \rangle$ is said to be \dn{strictly $w$-positive} if there is a homomorphism $\phi : G \to \mathbb{Z}$ such that if $v$ is a nonempty prefix of $w$, $\phi(v) > 0$.
\end{defn}
\begin{theorem}[\cite{Ivanov2001}, Corollary 5.2] \label{thm:strictly-w-positive-decidable-WP}
	If $\Gp \langle A \mid w = \epsilon \rangle$ is a strictly $w$-positive presentation, and the word $w$ is reduced, then the inverse monoid presented by $\Inv \langle A \mid w = \epsilon \rangle$ has decidable word problem.
\end{theorem}
An example of a class of groups with this type of presentation is $\BS(n, n) = \Gp \langle a, b \mid ba^n b^{-1} a^{-n} = \epsilon \rangle$ for $n > 0$.\footnote{The notation $\BS(m, n)$ is used since these are Baumslag-Solitar groups, which in general have presentation $\BS(m, n) = \Gp \langle a, b \mid ba^mb^{-1}a^{-n}\rangle = \Gp \langle a, b \mid [b, a^n] = \epsilon \rangle$. These have various interesting properties, and some arise in topological settings.} Mapping both $a$ and $b$ to 1 gives a homomorphism $\phi$ into $\mathbb{Z}$, since $\phi(b) + n\phi(a) - \phi(b) - n\phi(a) = 0$. We then check all the proper prefixes map to positive integers; indeed
\begin{itemize}
	\item $\phi(b) = 1 > 0$,
	\item $\phi(ba^i) = 1 + i > 0$ for all $1 \le i \le n$,
	\item $\phi(ba^nb^{-1}) = n > 0$ for all $1 \le i \le n$ and
	\item $\phi(ba^nb^{-1}a^{-j}) = n - j > 0$ for all $1 \le j < n$.
\end{itemize}
So the presentation is strictly $w$-positive and hence $\Inv \langle a, b \mid ba^nb^{-1}a^{-n} = \epsilon \rangle$ has solvable word problem.
%A more general form of this example appears as theorem 5.3(b) in the paper: recall that the \dn{commutator} $[a, b]$ of two elements $a, b$ in a group or inverse monoid is the product $aba^{-1}b^{-1}$. It is clear then that $\BS(n, n) = \langle a, b \mid [b,a^n] = \epsilon \rangle$; Ivanov, et al. show that any product o

A related result --- another special case in which the word problem is solvable --- is given by an earlier theorem of Birget, Margolis and Meakin \cite{Birget1994}:
\begin{theorem}[\cite{Birget1994}, Theorem 2.3]
	If $M = \Inv \langle A \mid w = \epsilon\rangle$ and $w$ is idempotent in the free inverse monoid, i.e. $w^2 = w$ in $\Inv \langle A \mid \rangle$, then $M$ has decidable word problem. \label{thm:idempotent-generated-WP-decidable}
\end{theorem}
Another characterisation of this condition that $w$ is idempotent in the free inverse monoid is that $w$ is in the Dyck language over $\Abar$. The \dn{Dyck language} over $A$ consists of all strings of balanced bracketed expressions, where each letter in $A$ is regarded as a type of opening bracket and each letter in $A^{-1}$ as a type of closing bracket.
Note that in this example, $M$ is not a strictly $w$-positive presentation, but it is simply `$w$-positive': if we weaken the definition to require only that $\phi(v) \ge 0$ for any prefix $v$, then $M$ satisfies this condition.

The proofs of both of these theorems rely heavily on the notion of so-called Sch√ºtzenberger automata --- deterministic automata whose accepted language characterises an element in an inverse monoid given by a presentation --- and on Stephen's construction of these automata using Munn trees (which we saw in \cref{sec:free-inverse-monoids}). These automata, and the mentioned construction, are described in detail in \cite{Stephen1990}.

\section{Related questions}
In this project, we have mostly concerned ourselves with the word problem for one-relation semigroups. We have looked in detail at the one-relation special monoids, using rewriting systems to show the solution to their word problem and glean some information about their structure. We also examined various reductions of the one-relation semigroup problem, with particular focus on the one-relation special inverse monoids, which have intriguing connections to the one-relation special monoids we considered first. Finally, we surveyed some special cases of the one-relation inverse monoid problem which have been solved, showing some of the directions that researchers are looking in to solve the general problem.

One natural inclination given this vantage point is to try and `connect the dots' between the one-relation special monoid and inverse monoid cases. There are, however, many other natural questions which could be answered about one-relation semigroups, such as whether other decision problems are solvable: the conjugacy and isomorphism problems that Dehn posed, for example, or very slightly more exotic ones such as the divisibility problem. Zhang, for instance, investigates the divisibility problem for special one-relation monoids in the same paper \cite{Zhang1992a}, making fruitful use of rewriting systems once again. Zhang also reduces the conjugacy problem for these monoids to that of their groups of units in \cite{Zhang1991}.

Another possible avenue of exploration is to ask how difficult the word problem is to solve, rather than just asking whether it is possible. We have been focussed on showing that the word problem is decidable, in the sense that it is recognisable by a Turing machine. One might ask if the word problem is recognisable by less powerful machines, such as deterministic automata. There are many general results in this vein; e.g. Anisimov's theorem states that the word problem of a group is regular if and only if the group is finite, and the same is true for semigroups. Muller and Schupp proved that the word problem of a group is context-free if and only if the group is virtually free, i.e. it contains a free subgroup of finite index. Some work on this question has been done to do with the structures we have been studying --- for example, in \cite{Margolis1993}, the inverse monoids with idempotent relator we described in \cref{thm:idempotent-generated-WP-decidable} are shown to have context-free word problem.

To conclude, this project has attempted to illuminate a small corner of one-relation semigroup theory. It raises a wide variety of connected questions whose answers involve many different areas of mathematics; we hope the reader is convinced of the interest in studying these structures, and that they have seen some stimulating mathematics on the way.


\appendix
\section{A program for computing \texorpdfstring{E(M)}{$E(M)$}} \label{sec:E(M)-program}

In \cref{sec:constructing-genset}, we computed the generating sets $E(M)$ and the sets $C_k$ as described in \cite{Zhang1992a} using a simple GAP program, reproduced below.

\inputminted[linenos=true,mathescape,tabsize=2,breaklines]{gap}{../ors.g}
\clearpage

\printbibliography

\printindex

\end{document}
